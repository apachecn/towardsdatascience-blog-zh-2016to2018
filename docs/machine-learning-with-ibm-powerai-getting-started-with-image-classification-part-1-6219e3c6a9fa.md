# ä½¿ç”¨ IBM PowerAI çš„æœºå™¨å­¦ä¹ ä¸­çš„å›¾åƒåˆ†ç±»åŸºç¡€(ç¬¬ 1 éƒ¨åˆ†)

> åŸæ–‡ï¼š<https://towardsdatascience.com/machine-learning-with-ibm-powerai-getting-started-with-image-classification-part-1-6219e3c6a9fa?source=collection_archive---------4----------------------->

![](img/0db06c90c94b389cb90a9499af6e281a.png)

[IBM Power Systems](https://www.ibm.com/power)

# ä»‹ç»

å›¾åƒåˆ†ç±»å·²ç»æˆä¸ºå±•ç¤ºæœºå™¨å­¦ä¹ çš„å…³é”®è¯•ç‚¹ç”¨ä¾‹ä¹‹ä¸€ã€‚åœ¨è¿™ç¯‡çŸ­æ–‡ä¸­ï¼Œæˆ‘è¯•å›¾æè¿°å¦‚ä½•ä½¿ç”¨ IBM PowerAI å®ç°è¿™æ ·ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼Œå¹¶åœ¨ IBM Power ç³»ç»Ÿä¸Šè¿è¡Œæ—¶æ¯”è¾ƒ GPU å’Œ CPU çš„æ€§èƒ½ã€‚

# äººå·¥æ™ºèƒ½

äººå·¥æ™ºèƒ½ç›®å‰è¢«è§†ä¸ºè®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒå¤„ç†è®©è®¡ç®—æœºæ‰§è¡Œåƒè§†è§‰è¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€è®¤çŸ¥å†³ç­–ã€è¯­è¨€ç¿»è¯‘ç­‰ä¼ ç»Ÿä¸Šè¢«è®¤ä¸ºæ˜¯äººç±»æ™ºèƒ½çš„ä»»åŠ¡ã€‚

# æœºå™¨å­¦ä¹ 

æœºå™¨å­¦ä¹ é€šå¸¸è¢«è§†ä¸ºäººå·¥æ™ºèƒ½çš„ä¸€ç§åº”ç”¨ï¼Œå®ƒè‡´åŠ›äºèµ‹äºˆç³»ç»Ÿå­¦ä¹ å’Œæ ¹æ®ç»éªŒæ”¹è¿›çš„èƒ½åŠ›ï¼Œè€Œæ— éœ€æ˜¾å¼ç¼–ç æ‰€æœ‰ä»»åŠ¡ã€‚

# æ·±åº¦å­¦ä¹ 

æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå…¶ä¸­ç³»ç»Ÿå¯ä»¥åˆ©ç”¨å¸¦æ ‡ç­¾çš„è®­ç»ƒæ•°æ®(æœ‰ç›‘ç£çš„)æˆ–æ— æ ‡ç­¾çš„è®­ç»ƒæ•°æ®(æ— ç›‘ç£çš„)è¿›è¡Œå­¦ä¹ ã€‚æ·±åº¦å­¦ä¹ é€šå¸¸ä½¿ç”¨åˆ†å±‚çš„äººå·¥ç¥ç»ç½‘ç»œæ¥æ‰§è¡Œä»»åŠ¡ã€‚

# äººå·¥ç¥ç»ç½‘ç»œ

äººå·¥ç¥ç»ç½‘ç»œæ˜¯å—ç”Ÿç‰©ç¥ç»ç½‘ç»œå¯å‘çš„ç³»ç»Ÿï¼Œå¯ä»¥ä»¥æƒŠäººçš„ç²¾åº¦æ‰§è¡ŒæŸäº›ä»»åŠ¡ï¼Œå¦‚å›¾åƒåˆ†ç±»ã€‚ä¾‹å¦‚ï¼Œå¯¹äºå›¾åƒåˆ†ç±»ï¼Œç»™åŠ¨ç‰©çš„ä¸€ç»„å›¾åƒæä¾›æ ‡è®°ã€‚è¿™æ˜¯è®­ç»ƒæ•°æ®ã€‚äººå·¥ç¥ç»ç½‘ç»œé€šè¿‡ä¸€ç³»åˆ—æ­¥éª¤(æˆ–å±‚)ï¼Œå¸®åŠ©ç³»ç»Ÿå­¦ä¹ å°†æœªæ ‡è®°çš„å›¾åƒ(æœ¬æ–‡æ‰€ç¤ºç¤ºä¾‹ä¸­çš„çŒ©çŒ©å›¾åƒ)åˆ†ç±»ä¸ºå±äºæŸä¸ªç¾¤ä½“çš„èƒ½åŠ›ï¼ŒåŒæ—¶å¾—å‡ºå‡†ç¡®åº¦åˆ†æ•°ã€‚

æ·±åº¦å­¦ä¹ åœ¨ä½ çš„ä¸šåŠ¡ä¸­æœ‰å‡ ä¸ªåº”ç”¨ï¼Œä»æ‰‹æœºä¸ªäººåŠ©ç†åˆ°è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼Œå¿«é€Ÿå˜åŒ–çš„æ¨¡å¼è¢«ç”¨äºå®æ—¶åˆ†ç±»ç‰©ä½“ã€‚

# ä»€ä¹ˆæ˜¯ IBM PowerAIï¼Ÿ

IBM PowerAI è½¯ä»¶è®©æ‚¨å¯ä»¥åœ¨åŒ…å« GPU çš„ IBM POWER9 æœåŠ¡å™¨ä¸Šè½»æ¾è¿è¡Œæ‰€æœ‰æµè¡Œçš„æœºå™¨å­¦ä¹ æ¡†æ¶ã€‚CPU æ˜¯ä¸ºä¸²è¡Œå¤„ç†è€Œè®¾è®¡å’Œæ„å»ºçš„ï¼ŒåŒ…å«å°‘é‡å†…æ ¸ï¼Œè€Œ GPU å¯ä»¥åŒ…å«æ•°åƒä¸ªæ›´å°çš„å†…æ ¸ï¼Œå¹¶ä¾èµ–äºä»»åŠ¡çš„å¹¶è¡Œå¤„ç†ã€‚ç”¨äºæœºå™¨å­¦ä¹ çš„ä»»åŠ¡æ˜¯ GPU çš„å…³é”®åº”ç”¨ã€‚çœ‹çœ‹ IBM Power System [AC922](https://www.ibm.com/us-en/marketplace/power-systems-ac922) æœåŠ¡å™¨ï¼Œå®ƒè¢«å¹æ§ä¸ºå¸‚åœºä¸Šè¿è¡Œä¼ä¸šäººå·¥æ™ºèƒ½ä»»åŠ¡çš„æœ€ä½³æœåŠ¡å™¨ä¹‹ä¸€ã€‚IBM PowerAI ç›®å‰åŒ…æ‹¬ä»¥ä¸‹æ¡†æ¶ï¼›

![](img/1c4b8070b9da2b77eeaf4f49d71ff7bc.png)

Source: [https://www.ibm.com/us-en/marketplace/deep-learning-platform](https://www.ibm.com/us-en/marketplace/deep-learning-platform)

# å½“å‰è®¾ç½®

å¯¹äºè¿™ä¸ªæ¼”ç¤ºï¼Œæˆ‘åœ¨ä¸€ä¸ªè¿è¡Œ Ubuntu on Power çš„è™šæ‹Ÿæœºä¸Šä½¿ç”¨äº†ä¸€ä¸ªå®¹å™¨( **ppc64le** )ï¼Œæ‰˜ç®¡åœ¨ [Nimbix Cloud](https://www.nimbix.net/) ä¸Šã€‚

å®¹å™¨æ˜¯å›¾åƒçš„è¿è¡Œå®ä¾‹ã€‚æ˜ åƒæ˜¯åŒ…å«æ“ä½œç³»ç»Ÿã€è½¯ä»¶å’Œåº”ç”¨ç¨‹åºä»£ç çš„æ¨¡æ¿ï¼Œæ‰€æœ‰è¿™äº›éƒ½æ‰“åŒ…åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­ã€‚ä½¿ç”¨ Dockerfile å®šä¹‰æ˜ åƒï¼Œdocker file æ˜¯é…ç½®æ˜ åƒçš„æ­¥éª¤åˆ—è¡¨ã€‚æ„å»º Dockerfile æ˜¯ä¸ºäº†åˆ›å»ºä¸€ä¸ªæ˜ åƒï¼Œè¿è¡Œè¿™ä¸ªæ˜ åƒæ˜¯ä¸ºäº†è·å¾—ä¸€ä¸ªè¿è¡Œå®¹å™¨ã€‚è¦è¿è¡Œæ˜ åƒï¼Œæ‚¨éœ€è¦åœ¨è™šæ‹Ÿæœºä¸Šå®‰è£…å’Œé…ç½® Docker å¼•æ“ã€‚

è¿™æ˜¯æˆ‘ç”¨è¿‡çš„ Dockerfile ï¼Œç”± [Indrajit Poddar](https://www.linkedin.com/in/ipoddar) ç¼–å†™ã€‚è¿™æ‘˜è‡ª [this Github](https://github.com/ibmsoe/Dockerfiles/blob/master/powerai-examples/Dockerfile) é¡µé¢ã€‚

è¿™ç”¨ Jupyter Notebookã€iTorch å†…æ ¸(æˆ‘ä»¬å°†åœ¨ç¬¬äºŒéƒ¨åˆ†è®¨è®º)å’Œä¸€äº›åŸºæœ¬ TensorFlow ç¤ºä¾‹æ„å»ºäº†ä¸€ä¸ªæ˜ åƒã€‚

**TensorFlow** æ˜¯ä¸€ä¸ªé¢å‘æœºå™¨å­¦ä¹ åº”ç”¨çš„å¼€æºã€å¯æ‰©å±•åº“ï¼ŒåŸºäºå¯ä»¥æ„å»ºå’Œæ‰§è¡Œçš„æ•°æ®æµå›¾çš„æ¦‚å¿µã€‚ä¸€ä¸ªå›¾å¯ä»¥åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼ŒèŠ‚ç‚¹å’Œè¾¹(æˆ–å¼ é‡)ã€‚å®ƒé™„å¸¦äº†ä¸€ä¸ª Python APIï¼Œå¾ˆå®¹æ˜“ç»„è£…ç½‘ç»œã€åˆ†é…å‚æ•°å’Œè¿è¡Œè®­ç»ƒæ¨¡å‹ã€‚

ä»¥ä¸‹æ­¥éª¤ç”±[è‹±å¾·æ‹‰å‰ç‰¹Â·æ³¢å¾·è¾¾å°”](https://www.linkedin.com/in/ipoddar)æ¼”ç¤ºã€‚ä»–åœ¨ Nimbix Cloud ä¸Šæ„å»ºäº†ä¸€ä¸ªæµ‹è¯•æ˜ åƒï¼Œè¯¥æ˜ åƒå°†åœ¨éƒ¨ç½²åå‡ åˆ†é’Ÿå†…è¿è¡Œä¸Šè¿°æœåŠ¡ã€‚

ä»¥ä¸‹å‘½ä»¤ç”¨äºéªŒè¯ GPU æ˜¯å¦è¿æ¥åˆ°å®¹å™¨ã€‚

```
root@JARVICENAE-0A0A1841:/usr/lib/nvidia-384# **nvidia-smi**Thu Feb 1 23:45:11 2018+ â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” -+| NVIDIA-SMI 384.111 Driver Version: 384.111 || â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” -+ â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” + â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” +| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. ||===============================+======================+======================|| 0 Tesla P100-SXM2â€¦ Off | 00000003:01:00.0 Off | 0 || N/A 40C P0 42W / 300W | 299MiB / 16276MiB | 0% Default |+ â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” -+| Processes: GPU Memory || GPU PID Type Process name Usage ||=============================================================================|+ â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” -+
```

æˆ‘çœ‹åˆ°ä¸€ä¸ªè‹±ä¼Ÿè¾¾ç‰¹æ–¯æ‹‰ P100 å›¾å½¢å¤„ç†å™¨è¿æ¥ã€‚ä»¥ä¸‹å‘½ä»¤æ˜¾ç¤ºäº†å·²å®‰è£…çš„ Jupyter Notebook å®ä¾‹ä»¥åŠç¨åå°†ç”¨äºèº«ä»½éªŒè¯çš„ç›¸å…³ä»¤ç‰Œã€‚

```
root@JARVICENAE-0A0A1841:/usr/lib/nvidia-384# jupyter notebook list
Currently running servers:
[http://0.0.0.0:8889/?token=d0f34d33acc9febe500354a9604462e8af2578f338981ad1](http://0.0.0.0:8889/?token=d0f34d33acc9febe500354a9604462e8af2578f338981ad1) :: /opt/DL/torch
[http://0.0.0.0:8888/?token=befd7faf9b806b6918f0618a28341923fb9a1e77d410b669](http://0.0.0.0:8888/?token=befd7faf9b806b6918f0618a28341923fb9a1e77d410b669) :: /opt/DL/caffe-ibm
[http://0.0.0.0:8890/?token=a9448c725c4ce2af597a61c47dcdb4d1582344d494bd132f](http://0.0.0.0:8890/?token=a9448c725c4ce2af597a61c47dcdb4d1582344d494bd132f) :: /opt/DL/tensorflow
root@JARVICENAE-0A0A1841:/usr/lib/nvidia-384#
```

# å¼€å§‹å›¾åƒåˆ†ç±»

## ä»€ä¹ˆæ˜¯å’–å•¡ï¼Ÿ

**Caffe** (ç”¨äºå¿«é€Ÿç‰¹å¾åµŒå…¥çš„å·ç§¯æ¶æ„)æ˜¯åœ¨ä¼¯å…‹åˆ©è§†è§‰å’Œå­¦ä¹ ä¸­å¿ƒå¼€å‘çš„ã€‚å®ƒæ˜¯ä¸€ä¸ªç”¨äºæ‰§è¡Œå›¾åƒåˆ†ç±»ç­‰ä»»åŠ¡çš„å¼€æºæ¡†æ¶ã€‚å®ƒæ”¯æŒ **CUDA** ï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼Œå…·æœ‰é¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå› æ­¤æ˜¯è¿™ä¸ªæ¼”ç¤ºçš„ä¸€ä¸ªå¥½é€‰æ‹©ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ Python æ¥æ‰§è¡Œæ‰€æœ‰çš„ä»»åŠ¡ã€‚ä»¥ä¸‹æ­¥éª¤æ˜¯é€šè¿‡ Jupyter ç¬”è®°æœ¬å®Œæˆçš„ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬è®¾ç½® Pythonã€ [Numpy](http://www.numpy.org/) å’Œ [Matplotlib](https://matplotlib.org/) ã€‚

```
import numpy as npimport matplotlib.pyplot as plt# display plots in this notebook%matplotlib inline# set display defaultsplt.rcParams[â€˜figure.figsizeâ€™] = (10, 10) # large imagesplt.rcParams[â€˜image.interpolationâ€™] = â€˜nearestâ€™ # donâ€™t interpolate: show square pixelsplt.rcParams[â€˜image.cmapâ€™] = â€˜grayâ€™ # use grayscale output rather than a (potentially misleading) color heatmap# Then, we load Caffe. The caffe module needs to be on the Python path;# weâ€™ll add it here explicitly.import syscaffe_root = â€˜../â€™ # this file should be run from {caffe_root}/examples (otherwise change this line)sys.path.insert(0, caffe_root + â€˜pythonâ€™)import caffe
```

# ä»€ä¹ˆæ˜¯å’–å•¡å› ï¼Ÿ

**Caffenet** æ˜¯ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œç”¨æ¥ä¸ **CUDA** æ¥å£ï¼Œä¸»è¦ç›®çš„æ˜¯å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»ã€‚Caffenet æ˜¯ **Alexnet** çš„å˜ç§ã€‚Alexnet çš„åˆ›å»ºè€…åœ¨ 2015 å¹´åšäº†ä¸€ä¸ªå±•ç¤ºï¼Œè¿™é‡Œæ˜¯ã€‚åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬ä¸‹è½½äº†ä¸€ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹ã€‚

```
import osif os.path.isfile(caffe_root + â€˜models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodelâ€™):print â€˜CaffeNet found.â€™else:print â€˜Downloading pre-trained CaffeNet modelâ€¦â€™!../scripts/download_model_binary.py ../models/bvlc_reference_caffenet
```

è¿™æ˜¯è¾“å‡ºã€‚

```
CaffeNet found.
Downloading pre-trained CaffeNet model... 
â€¦100%, 232 MB, 42746 KB/s, 5 seconds passed
```

ç„¶åï¼Œæˆ‘ä»¬åœ¨ CPU æ¨¡å¼ä¸‹åŠ è½½ Caffeï¼Œå¹¶è¿›è¡Œè¾“å…¥é¢„å¤„ç†ã€‚

```
caffe.set_mode_cpu()model_def = caffe_root + â€˜models/bvlc_reference_caffenet/deploy.prototxtâ€™model_weights = caffe_root + â€˜models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodelâ€™net = caffe.Net(model_def, # defines the structure of the modelmodel_weights, # contains the trained weightscaffe.TEST) # use test mode (e.g., donâ€™t perform dropout)
```

ç”¨çš„æ˜¯ Caffenet çš„â€˜caffe . io . transformerâ€™ã€‚è¿™æ˜¯æ‰€æœ‰ç¤ºä¾‹ä¸­ä½¿ç”¨çš„é»˜è®¤è½¬æ¢å™¨ã€‚å®ƒæ ¹æ®æä¾›çš„è¾“å…¥ä¸ºå›¾åƒåˆ›å»ºä¸€ä¸ªå˜æ¢çš„å¹³å‡å€¼ã€‚Caffenet è¢«è®¾ç½®ä¸ºè·å– BGR æ ¼å¼çš„è¾“å…¥å›¾åƒï¼Œå…¶å€¼åœ¨ 0 åˆ° 255 çš„èŒƒå›´å†…ã€‚æ‰§è¡Œè½¬æ¢ä»¥åŠ è½½ RGB æ ¼å¼çš„å€¼åœ¨ 0 åˆ° 1 èŒƒå›´å†…çš„å›¾åƒï¼Œä½œä¸º Matplotlib æ‰€éœ€çš„è¾“å…¥ã€‚

```
# load the mean ImageNet image (as distributed with Caffe) for subtractionmu = np.load(caffe_root + â€˜python/caffe/imagenet/ilsvrc_2012_mean.npyâ€™)mu = mu.mean(1).mean(1) # average over pixels to obtain the mean (BGR) pixel valuesprint â€˜mean-subtracted values:â€™, zip(â€˜BGRâ€™, mu)# create transformer for the input called â€˜dataâ€™transformer = caffe.io.Transformer({â€˜dataâ€™: net.blobs[â€˜dataâ€™].data.shape})transformer.set_transpose(â€˜dataâ€™, (2,0,1)) # move image channels to outermost dimensiontransformer.set_mean(â€˜dataâ€™, mu) # subtract the dataset-mean value in each channeltransformer.set_raw_scale(â€˜dataâ€™, 255) # rescale from [0, 1] to [0, 255]transformer.set_channel_swap(â€˜dataâ€™, (2,1,0)) # swap channels from RGB to BGR
```

æ¢å¥è¯è¯´ï¼Œè®¡ç®—æœºç°åœ¨å¯ä»¥é€šè¿‡é¦–å…ˆå°†å›¾åƒè½¬æ¢ä¸º RGB å€¼çš„æ•°ç»„æ¥å­¦ä¹ å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»ã€‚ç„¶åï¼Œæ‰«æè¿™äº›å€¼ä»¥å¯»æ‰¾å·²ç»ä¸é¢„è®­ç»ƒæ¨¡å‹ä¸­çš„å¦ä¸€ä¸ªå›¾åƒç›¸åŒ¹é…çš„å€¼çš„æ¨¡å¼ã€‚åœ¨æ¯”è¾ƒæ—¶ï¼Œä¼šç”Ÿæˆç½®ä¿¡åº¦åº¦é‡ï¼Œæ˜¾ç¤ºåˆ†ç±»çš„å‡†ç¡®ç¨‹åº¦ã€‚

è¿™æ˜¯è¾“å‡ºã€‚

```
mean-subtracted values: [(â€˜Bâ€™, 104.0069879317889), (â€˜Gâ€™, 116.66876761696767), (â€˜Râ€™, 122.6789143406786)]
```

# åˆ†ç±»

è¿™é‡Œï¼Œæˆ‘ä»¬è®¾ç½®å›¾åƒçš„é»˜è®¤å¤§å°ã€‚è¿™å¯ä»¥æ ¹æ®æ‚¨çš„è¾“å…¥è¿›è¡Œæ›´æ”¹ã€‚

```
net.blobs[â€˜dataâ€™].reshape(50, # batch size3, # 3-channel (BGR) images720, 720) # image size is 720x720
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä» Wiki Commons åº“ä¸­åŠ è½½ä¸€åªçŒ©çŒ©çš„å›¾åƒã€‚

```
# download the imagemy_image_url = â€œhttps://upload.wikimedia.org/wikipedia/commons/b/be/Orang_Utan%2C_Semenggok_Forest_Reserve%2C_Sarawak%2C_Borneo%2C_Malaysia.JPG" # paste your URL here!wget -O image.jpg $my_image_url# transform it and copy it into the netimage = caffe.io.load_image(â€˜image.jpgâ€™)transformed_image = transformer.preprocess(â€˜dataâ€™, image)plt.imshow(image)
```

è¿™æ˜¯è¾“å‡ºã€‚

```
--2018-02-02 00:27:52--  [https://upload.wikimedia.org/wikipedia/commons/b/be/Orang_Utan%2C_Semenggok_Forest_Reserve%2C_Sarawak%2C_Borneo%2C_Malaysia.JPG](https://upload.wikimedia.org/wikipedia/commons/b/be/Orang_Utan%2C_Semenggok_Forest_Reserve%2C_Sarawak%2C_Borneo%2C_Malaysia.JPG)Resolving upload.wikimedia.org (upload.wikimedia.org)... 198.35.26.112, 2620:0:863:ed1a::2:bConnecting to upload.wikimedia.org (upload.wikimedia.org)|198.35.26.112|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 1443340 (1.4M) [image/jpeg]Saving to: 'image.jpg'image.jpg           100%[===================>]   1.38M  5.25MB/s    in 0.3s2018-02-02 00:27:54 (5.25 MB/s) - 'image.jpg' saved [1443340/1443340]
```

![](img/8cc6bdb0a059ff29d7a35cf8838df37e.png)

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»ã€‚

```
# copy the image data into the memory allocated for the netnet.blobs[â€˜dataâ€™].data[â€¦] = transformed_image# perform classificationoutput = net.forward()â€‹output_prob = output[â€˜probâ€™][0] # the output probability vector for the first image in the batchâ€‹print â€˜predicted class is:â€™, output_prob.argmax()
```

è¾“å‡ºä¸º'**é¢„æµ‹ç±»ä¸º:365** 'ã€‚

ä¸Šé¢çš„è¾“å‡ºå°†å›¾åƒåˆ†ç±»ä¸ºç±»åˆ« 365ã€‚è®©æˆ‘ä»¬åŠ è½½ ImageNet æ ‡ç­¾å¹¶æŸ¥çœ‹è¾“å‡ºã€‚

```
# load ImageNet labelslabels_file = caffe_root + â€˜data/ilsvrc12/synset_words.txtâ€™if not os.path.exists(labels_file):!../data/ilsvrc12/get_ilsvrc_aux.shlabels = np.loadtxt(labels_file, str, delimiter=â€™\tâ€™)print â€˜output label:â€™, labels[output_prob.argmax()]
```

è¿™æ˜¯è¾“å‡ºã€‚ä¸Šè¯¾æ˜¯å¯¹çš„ï¼

```
output label: n02480495 orangutan, orang, orangutang, Pongo pygmaeus
```

ä¸‹é¢çš„ä»£ç å¯ä»¥å¸®åŠ©ä½ æ‰¾åˆ°å…¶ä»–çš„é¡¶çº§ç±»ã€‚

```
# sort top five predictions from softmax outputtop_inds = output_prob.argsort()[::-1][:5] # reverse sort and take five largest itemsprint â€˜probabilities and labels:â€™zip(output_prob[top_inds], labels[top_inds])
```

è¿™æ˜¯è¾“å‡ºã€‚

```
probabilities and labels:
[(0.96807814, 'n02480495 orangutan, orang, orangutang, Pongo pygmaeus'),(0.030588957, 'n02492660 howler monkey, howler'),(0.00085891742, 'n02493509 titi, titi monkey'),(0.00015429058, 'n02493793 spider monkey, Ateles geoffroyi'),(7.259626e-05, 'n02488291 langur')]
```

# åˆ†æ GPU æ€§èƒ½

è¿™æ˜¯åœ¨çº¯ CPU æ¨¡å¼ä¸‹æ‰§è¡Œåˆ†ç±»æ‰€èŠ±è´¹çš„æ—¶é—´ã€‚

```
%timeit net.forward()
```

è¿™æ˜¯è¾“å‡ºã€‚

```
OUTPUT: 1 loop, best of 3: 3.06 s per loop
```

æ¯ä¸ªå¾ªç¯ä¸‰ç§’é’Ÿç›¸å½“é•¿ã€‚è®©æˆ‘ä»¬åˆ‡æ¢åˆ° GPU æ¨¡å¼ï¼Œæ‰§è¡ŒåŒæ ·çš„æ“ä½œã€‚

```
caffe.set_device(0) # if we have multiple GPUs, pick the first onecaffe.set_mode_gpu()net.forward() # run once before timing to set up memory%timeit net.forward()
```

è¿™æ˜¯è¾“å‡ºã€‚

```
OUTPUT: 1 loop, best of 3: 11.4 ms per loop
```

è¿™æ˜¯ 3048.6 æ¯«ç§’çš„æ”¹è¿›ï¼è¿™ç¯‡åšå®¢çš„ç¬¬ä¸€éƒ¨åˆ†åˆ°æ­¤ç»“æŸã€‚æˆ‘ä¸ºè¯­æ³•é”™è¯¯é“æ­‰ï¼Œå¦‚æœæœ‰çš„è¯ã€‚

åœ¨ä¸‹ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†äº†è§£å¦‚ä½•ä½¿ç”¨ NVIDIA Digits è®­ç»ƒæ‚¨è‡ªå·±çš„æ¨¡å‹ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ Torchã€‚

å¦‚æœä½ å–œæ¬¢è¿™é¦–æ›²å­ï¼Œé‚£å°±é¼“æŒå§ğŸ‘ğŸ»(å¯ä»¥ä¸æ­¢ä¸€æ¬¡é¼“æŒ)ï¼ä½ ä¹Ÿå¯ä»¥åœ¨ç½‘ä¸Šçš„æŸä¸ªåœ°æ–¹åˆ†äº«ï¼Œè¿™æ ·å…¶ä»–äººä¹Ÿå¯ä»¥é˜…è¯»ã€‚

å…è´£å£°æ˜:æœ¬ç½‘ç«™ä¸Šçš„å¸–å­æ˜¯æˆ‘è‡ªå·±çš„ï¼Œä¸ä¸€å®šä»£è¡¨ IBM çš„ç«‹åœºã€ç­–ç•¥æˆ–è§‚ç‚¹ã€‚

ä½œè€…:[ä¹Œå½­å¾·æ‹‰Â·æ‹‰è©¹](https://www.linkedin.com/in/upendra-rajan-b208602a/)