# å¤šæ ‡ç­¾æ„å›¾åˆ†ç±»

> åŸæ–‡ï¼š<https://towardsdatascience.com/multi-label-intent-classification-1cdd4859b93?source=collection_archive---------5----------------------->

æœ‰å¾ˆå¤šåº”ç”¨éœ€è¦æ–‡æœ¬åˆ†ç±»ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥è¯´æ„å›¾åˆ†ç±»ã€‚ç°åœ¨ï¼Œæ‰€æœ‰çš„ä¸œè¥¿éƒ½éœ€è¦åˆ†ç±»ï¼Œå°±åƒå†…å®¹ä¸€æ ·ï¼Œäº§å“ä¹Ÿç»å¸¸è¢«åˆ†ç±»ã€‚

ä½†æ˜¯ç½‘ä¸Šç»å¤§å¤šæ•°çš„æ–‡æœ¬åˆ†ç±»æ–‡ç« å’Œæ•™ç¨‹éƒ½æ˜¯é‚®ä»¶åƒåœ¾è¿‡æ»¤(spam vs. ham)ã€æƒ…æ„Ÿåˆ†æ(æ­£é¢ vs .è´Ÿé¢)ç­‰äºŒå…ƒæ–‡æœ¬åˆ†ç±»ã€‚æˆ‘ä»¬ç°å®ä¸–ç•Œçš„é—®é¢˜è¦æ¯”è¿™å¤æ‚å¾—å¤šã€‚å› æ­¤ï¼Œè¿™å°±æ˜¯æˆ‘è¦åœ¨è¿™ç¯‡åšå®¢ä¸­è§£é‡Šçš„ã€‚å°†æ–‡æœ¬åˆ†ç±»æˆå¤šä¸ªç±»åˆ«ã€‚

**é—®é¢˜é™ˆè¿°:**

æˆ‘ä¸ºæˆ‘çš„ GSoC é¡¹ç›®(Owasp SKF èŠå¤©æœºå™¨äºº)å¼€å‘äº†è¿™ä¸ªåˆ†ç±»å™¨ã€‚é—®é¢˜é™ˆè¿°æ˜¯é’ˆå¯¹ä¸åŒæ¼æ´çš„å®‰å…¨çŸ¥è¯†æ¡†æ¶çŸ¥è¯†åº“ã€‚å®ƒæä¾›äº†é’ˆå¯¹ä¸åŒæ¼æ´çš„æè¿°ã€è§£å†³æ–¹æ¡ˆå’Œä»£ç ç¤ºä¾‹ã€‚æ‰€ä»¥ï¼Œæˆ‘éœ€è¦å¯¹ç”¨æˆ·çš„æŸ¥è¯¢è¿›è¡Œåˆ†ç±»ï¼Œæ— è®ºä»–æ˜¯è¦æ±‚æè¿°ã€è§£å†³æ–¹æ¡ˆè¿˜æ˜¯ä»£ç ç¤ºä¾‹ã€‚

æˆ‘ä½¿ç”¨äº† [Python](https://www.python.org/) å’Œ [Jupyter Notebook](http://jupyter.org/) æ¥å¼€å‘æˆ‘ä»¬çš„ç³»ç»Ÿï¼Œä¾é  [Scikit-Learn](http://scikit-learn.org/stable/) ä½œä¸ºæœºå™¨å­¦ä¹ ç»„ä»¶ã€‚

æ•°æ®é›†çš„å‡†å¤‡:

å¯¹äºä»»ä½•ä¸åˆ†ç±»æˆ–æœºå™¨å­¦ä¹ ç›¸å…³çš„é—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦çš„æ˜¯æ ¼å¼è¿‡äºæ­£ç¡®çš„æ•°æ®ã€‚å› æ­¤ï¼Œé¦–å…ˆæˆ‘å°†è§£é‡Šæˆ‘å¦‚ä½•å‡†å¤‡æ„å›¾åˆ†ç±»çš„æ•°æ®é›†ã€‚

```
import json
import csv
with open("data.json",encoding='utf-8') as read_file:
        data = json.load(read_file)
```

å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹ data.json [ã€‚æˆ‘å°†å‡†å¤‡ CSV æ ¼å¼çš„æ•°æ®é›†ï¼Œå› ä¸ºå®ƒå¾ˆå®¹æ˜“è®­ç»ƒæ¨¡å‹ã€‚](https://github.com/Priya997/SKF-Chatbot/blob/master/Basic_Approach/Scripts_to_prepare_dataset/data.json)

```
#For parsing the Json
a=data['items']
#Declaration of liststitle=[]
ques=[]
sol=[]
code=[]#For accessing the title from Json and storing it in the list.
for d in a: 
   title.append((d['title']))
```

æˆ‘çš„æ–‡æœ¬åˆ†ç±»æ˜¯é’ˆå¯¹é—®ç­”ç±»ç³»ç»Ÿçš„ã€‚å› æ­¤ï¼Œæˆ‘éœ€è¦ç”Ÿæˆé—®é¢˜ï¼Œå› ä¸ºæˆ‘æå–äº†åˆ—è¡¨ä¸­çš„æ‰€æœ‰æ ‡é¢˜ã€‚

```
for t in title:
	ques.append("What is "+ t + " ?")
	ques.append("What does "+ t + " mean ?")
	ques.append("Tell me something about "+ t + " ?")
	ques.append(t)
	ques.append("Explain " + t +" ?")
	ques.append("Elaborate " + t +" ?")
	ques.append("Can you tell me about " + t + " ?")
	ques.append("What do you know about " + t + " ?")
	ques.append("What can you tell me about " + t + " ?")
	ques.append("I want to know about XSS " + t )
	ques.append("Do you have information about " + t + " ?")for t in title:
        sol.append("How to solve "+ t + " ?")
        sol.append("How to resolve "+ t + " ?")
        sol.append("How to mitigate "+ t + " ?")
        sol.append("Solution for "+ t)
        sol.append("Provide me some Solution for "+ t)
        sol.append("mitigation for "+ t)
        sol.append("How to stop "+ t + " ?")
        sol.append("How to defend "+ t + " ?")
        sol.append("How to get secured against "+ t + " ?")
        sol.append("Solution, "+t)

for t in title:
        code.append("Give me some sample code of "+ t )
        code.append("Code example of "+ t + " ?")
        code.append("Code of "+ t )
```

å› æ­¤ï¼Œé—®é¢˜éœ€è¦æ ¹æ®æè¿°ã€è§£å†³æ–¹æ¡ˆå’Œä»£ç è¿›è¡Œåˆ†ç±»ã€‚æ‰€ä»¥ï¼Œæˆ‘åšäº†ä¸‰ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªåˆ—è¡¨å­˜å‚¨ä¸€ä¸ªé—®é¢˜ã€‚

```
file=open("intent_data.csv","x")
file.write('class,question\n')
for x in ques:
		x=x.replace(",","")
		file.write('Description, '+x+"\n")	 
for y in sol:
		y=y.replace(",","")
		file.write('Solution, '+y+"\n")

for z in code:
		z=z.replace(",","")
		file.write('Code, '+z+"\n")

file.close()
```

![](img/47974d966a8a40a0295bc187c1b04d99.png)

æ‰€ä»¥ï¼Œç°åœ¨æ•°æ®å‡†å¤‡å¥½äº†ã€‚ä½ å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹å®Œæ•´æ•°æ®[ã€‚](https://github.com/Priya997/SKF-Chatbot/blob/master/Basic_Approach/datasets/intent_data.csv)

ä¸ºäº†æ›´å¥½åœ°ç†è§£å¦‚ä½•å‡†å¤‡æ•°æ®é›†ï¼Œæ‚¨ä¹Ÿå¯ä»¥æŸ¥çœ‹è¿™ä¸ª [jupyter ç¬”è®°æœ¬](https://github.com/Priya997/SKF-Chatbot/blob/master/Basic_Approach/notebook/intent_data_prepare.ipynb)ç¤ºä¾‹ã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»å‡†å¤‡å¥½æ•°æ®ğŸ˜„...æ˜¯æ—¶å€™ç”¨å®ƒå˜å˜é­”æœ¯äº†ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å¯¹æ„å›¾è¿›è¡Œåˆ†ç±»ã€‚

**è®©æˆ‘ä»¬å¯¼å…¥ä¸€äº›åº“:**

```
import pandas as pd
from io import StringIO
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.naive_bayes import MultinomialNB
```

é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä» CSV æ–‡ä»¶ä¸­æå–æ•°æ®ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨æ•°æ®å¸§ä¸­ã€‚

```
def get_data():
    df = pd.read_csv('datasets/intent_data.csv')
    return df
```

åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬å°†å‡†å¤‡å¥½æ•°æ®ä»¥å°†å…¶è¾“å…¥ç®—æ³•ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åœ¨**â€˜yâ€™**ä¸­è·å¾—å®Œæ•´çš„æ•°æ®ï¼Œå¹¶ä½¿ç”¨

```
**y=[col]**
```

ä¹‹åï¼Œä½¿ç”¨' **pd.notnull'** æ¥æ£€æŸ¥é—®é¢˜åˆ—ä¸­çš„æ•°æ®æ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºï¼Œåˆ™å°†åˆ é™¤æ•´è¡Œã€‚

> è¿™ä¸€æ­¥å¯¹äºè·å¾—é«˜è´¨é‡çš„å¹²å‡€æ•°æ®éå¸¸é‡è¦ã€‚å› ä¸ºï¼Œå¦‚æœæˆ‘ä»¬æœ‰å¥½çš„æ•°æ®ï¼Œæˆ‘ä»¬å°±ä¼šæœ‰å¥½çš„ç»“æœã€‚ğŸ˜ƒ

æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªæ–°çš„åˆ—**â€˜category _ idâ€™**ï¼Œå®ƒå°†ç»™å‡ºä¸€ä¸ªç­çº§ç¼–å·ã€‚ç±»ä¼¼äºæè¿°ï¼Œå®ƒå°†æ˜¯ 0ï¼Œè§£å†³æ–¹æ¡ˆ 1 å’Œä»£ç  2ã€‚

åˆ é™¤é‡å¤åï¼Œæˆ‘ä»¬å°†å¾—åˆ°ç±»ä¼¼è¿™æ ·çš„ä¸œè¥¿

```
category_id_df = y[['classs', 'category_id']].**drop_duplicates()**.sort_values('category_id')
**print(category_id_df)****classs                category_id**
0       Description         0
2       Solution            1
5081    Code                2
```

å¯ä»¥æŸ¥çœ‹ä¸‹é¢ data_prepare çš„ä»£ç ç‰‡æ®µã€‚

```
def data_prepare():
    col = ['classs', 'question']
    y=get_data()
    y = y[col]
    y = y[pd.notnull(y['question'])]
    y.columns = ['classs', 'question']
    y['category_id'] = y['classs'].factorize()[0]
    category_id_df = y[['classs', 'category_id']].drop_duplicates().sort_values('category_id')
    category_to_id = dict(category_id_df.values)
    id_to_category = dict(category_id_df[['category_id', 'classs']].values) **#This will add the column in our dataframe**
    return y
```

æˆ‘ä½¿ç”¨äº†å¤šé¡¹å¼æœ´ç´ è´å¶æ–¯ç®—æ³•è¿›è¡Œé¢„æµ‹ï¼Œå› ä¸ºæˆ‘å‘ç°å®ƒæ˜“äºå®ç°å¹¶ä¸”å…·æœ‰å¾ˆé«˜çš„å‡†ç¡®æ€§ã€‚

OneVsRest ç­–ç•¥å¯ç”¨äºå¤šæ ‡ç­¾å­¦ä¹ ï¼Œä¾‹å¦‚ï¼Œä½¿ç”¨åˆ†ç±»å™¨æ¥é¢„æµ‹å¤šä¸ªæ ‡ç­¾ã€‚æœ´ç´ è´å¶æ–¯æ”¯æŒå¤šç±»ï¼Œä½†æˆ‘ä»¬å¤„äºå¤šæ ‡ç­¾åœºæ™¯ä¸­ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬å°†æœ´ç´ è´å¶æ–¯åŒ…è£…åœ¨ OneVsRestClassifier ä¸­ã€‚

> **OneVsRest å¤šæ ‡ç­¾ç­–ç•¥**
> 
> å¤šæ ‡ç­¾ç®—æ³•æ¥å—å¤šä¸ªæ ‡ç­¾ä¸Šçš„äºŒè¿›åˆ¶æ©ç ã€‚æ¯ä¸ªé¢„æµ‹çš„ç»“æœå°†æ˜¯ä¸€ä¸ªç”± 0 å’Œ 1 ç»„æˆçš„æ•°ç»„ï¼Œç”¨äºæ ‡è®°å“ªäº›ç±»æ ‡ç­¾é€‚ç”¨äºæ¯ä¸ªè¡Œè¾“å…¥æ ·æœ¬ã€‚

ä¸ºäº†æ›´å¥½åœ°ç†è§£ä¸‹é¢çš„ä»£ç ç‰‡æ®µå’Œå¤šé¡¹å¼ Naive_bayesï¼Œè¯·å°è¯•[è¿™ä¸ª](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)ã€‚

ä¸€ä¸ªç®€çŸ­çš„æ¦‚è¿°æ˜¯:åœ¨è¿™é‡Œï¼Œæˆ‘å°†æˆ‘çš„æ•°æ®åˆ†ä¸ºæµ‹è¯•æ•°æ®å’Œè®­ç»ƒæ•°æ®ï¼Œç„¶åå°†è¿™äº›æ•°æ®è¾“å…¥åˆ°æ¨¡å‹ä¸­ã€‚

```
def naive_algo():
    tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')
    df=data_prepare()
    features = tfidf.fit_transform(df.question).toarray()
    labels = df.category_id
    features.shape
    X_train, X_test, y_train, y_test = train_test_split(df['question'], df['classs'], random_state = 0)
    count_vect = CountVectorizer()
    X_train_counts = count_vect.fit_transform(X_train)
    tfidf_transformer = TfidfTransformer()
    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)
    clf = MultinomialNB().fit(X_train_tfidf, y_train)
    return clf,count_vect
```

æˆ‘è¿˜å°è¯•äº†å…¶ä»–ç®—æ³•æˆ–æ¨¡å‹ï¼Œå¦‚çº¿æ€§ SVCã€é€»è¾‘å›å½’å’Œéšæœºæ£®æ—ã€‚ä½ å¯ä»¥çœ‹çœ‹è¿™é‡Œçš„é‚£ä¸ªã€‚

è¿™å°†ç»™æˆ‘ä»¬æœ€ç»ˆçš„é¢„æµ‹ã€‚

```
def predict(question):
    clf,count_vect=naive_algo()
    intent=clf.predict(count_vect.transform([question]))
    intent=str(intent).strip("['']")
    return intent
```

æœ€åï¼Œæˆ‘ä»¬è¾“å…¥é—®é¢˜ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™ predict å‡½æ•°ï¼Œç„¶åç­‰å¾…å˜é­”æœ¯ã€‚ğŸ˜

```
ques=input("Enter your question ")
x=predict(ques)
```

![](img/c3ee01909d8540bd7c36e922878e9ab3.png)

æ¼‚äº®ï¼Œå‡†ç¡®ï¼Œä¸æ˜¯å—ï¼Ÿ

æ‚¨å¯ä»¥æŸ¥çœ‹æœ¬[ç¬”è®°æœ¬](https://github.com/Priya997/SKF-Chatbot/blob/master/Basic_Approach/notebook/Intent_classifier.ipynb)ä»¥æ›´å¥½åœ°äº†è§£æ„å›¾åˆ†ç±»ã€‚

> æ„Ÿè°¢é˜…è¯»ï¼å¦‚æœä½ å–œæ¬¢å®ƒï¼Œè¯·é¼“æŒï¼Œè¯„è®º(è¯„è®ºæˆ–è´¨ç–‘)å¹¶åˆ†äº«å®ƒğŸ˜„
> 
> ä½ å¯ä»¥åœ¨ [Github](https://github.com/Priya997) ã€ [Linkedin](https://www.linkedin.com/in/priyanka997/) ã€ [Twitter](https://twitter.com/priyankajain997) ä¸Šå’Œæˆ‘è”ç³»ğŸ˜„

æ›´å¤šå†…å®¹ï¼Œè¯·ç‚¹å‡»ä¸‹é¢çš„â€œç»™æˆ‘ä¹°æ¯å’–å•¡â€å›¾æ ‡æ”¯æŒæˆ‘ã€‚

[![](img/50e94cd09638fbec196afd2091ddbace.png)](https://www.buymeacoffee.com/priyankajain97)