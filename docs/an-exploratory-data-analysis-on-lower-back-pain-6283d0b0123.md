# ä¸‹è…°ç—›çš„æ¢ç´¢æ€§æ•°æ®åˆ†æ

> åŸæ–‡ï¼š<https://towardsdatascience.com/an-exploratory-data-analysis-on-lower-back-pain-6283d0b0123?source=collection_archive---------6----------------------->

![](img/445402986f81edbe17bcc886bf0dcc1e.png)

Image collected from [https://unsplash.com/photos/XNRHhomhRU4](https://unsplash.com/photos/XNRHhomhRU4)

[**è…°ç—›**](https://www.healthline.com/health/back-pain) ï¼Œä¹Ÿå«**è…°ç—›**ï¼Œä¸æ˜¯ä¸€ç§ç—…ç—‡ã€‚è¿™æ˜¯å‡ ç§ä¸åŒç±»å‹çš„åŒ»å­¦é—®é¢˜çš„ç—‡çŠ¶ã€‚å®ƒé€šå¸¸ç”±ä¸‹èƒŒéƒ¨çš„ä¸€ä¸ªæˆ–å¤šä¸ªéƒ¨ä½çš„é—®é¢˜å¼•èµ·ï¼Œä¾‹å¦‚:

*   éŸ§å¸¦
*   è‚Œè‚‰
*   ç¥ç»ç´§å¼ 
*   æ„æˆè„ŠæŸ±çš„éª¨ç»“æ„ï¼Œç§°ä¸ºæ¤ä½“æˆ–æ¤éª¨

è…°éƒ¨ç–¼ç—›ä¹Ÿå¯èƒ½æ˜¯ç”±äºé™„è¿‘å™¨å®˜(å¦‚è‚¾è„)çš„é—®é¢˜å¼•èµ·çš„ã€‚

åœ¨è¿™ä¸ª [EDA](https://en.wikipedia.org/wiki/Exploratory_data_analysis) ä¸­ï¼Œæˆ‘å°†ä½¿ç”¨ä¸‹èƒŒéƒ¨ç–¼ç—›ç—‡çŠ¶[æ•°æ®é›†](https://www.kaggle.com/sammy123/lower-back-pain-symptoms-dataset)å¹¶å°è¯•æ‰¾å‡ºè¯¥æ•°æ®é›†çš„æœ‰è¶£è§è§£ã€‚æˆ‘ä»¬å¼€å§‹å§ï¼

# æ•°æ®é›†æè¿°

æ•°æ®é›†åŒ…å«:

*   **310** è§‚å¯Ÿç»“æœ
*   **12** ç‰¹å¾
*   **1** æ ‡ç­¾

## å¯¼å…¥å¿…è¦çš„åŒ…:

```
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inlineimport seaborn as sns
sns.set()
from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier, plot_importance
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix
```

è¯»å–`.csv`æ–‡ä»¶:

```
dataset = pd.read_csv("../input/Dataset_spine.csv")
```

æŸ¥çœ‹æ•°æ®é›†ä¸­çš„å‰ 5 è¡Œ:

```
dataset.head() # this will return top 5 rows 
```

ç§»é™¤è™šæ‹Ÿåˆ—:

```
# This command will remove the last column from our dataset.
del dataset["Unnamed: 13"]
```

## æ•°æ®é›†æ‘˜è¦:

[DataFrame.describe()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) æ–¹æ³•ç”Ÿæˆæè¿°æ€§ç»Ÿè®¡æ•°æ®ï¼Œè¿™äº›ç»Ÿè®¡æ•°æ®æ€»ç»“äº†æ•°æ®é›†åˆ†å¸ƒçš„é›†ä¸­è¶‹åŠ¿ã€ç¦»æ•£åº¦å’Œå½¢çŠ¶ï¼Œä¸åŒ…æ‹¬`NaN`å€¼ã€‚è¿™ä¸ªæ–¹æ³•å‘Šè¯‰æˆ‘ä»¬å…³äºæ•°æ®é›†çš„å¾ˆå¤šäº‹æƒ…ã€‚é‡è¦çš„ä¸€ç‚¹æ˜¯`describe()`æ–¹æ³•åªå¤„ç†æ•°å€¼ã€‚å®ƒä¸é€‚ç”¨äºä»»ä½•åˆ†ç±»å€¼ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¥ç†è§£ç”±`describe()`æ–¹æ³•ç”Ÿæˆçš„ç»Ÿè®¡æ•°æ®:

*   `count`å‘Šè¯‰æˆ‘ä»¬ä¸€ä¸ªç‰¹å¾ä¸­çš„`NoN-empty`è¡Œæ•°ã€‚
*   `mean`å‘Šè¯‰æˆ‘ä»¬è¯¥ç‰¹å¾çš„å¹³å‡å€¼ã€‚
*   `std`å‘Šè¯‰æˆ‘ä»¬è¯¥ç‰¹å¾çš„æ ‡å‡†åå·®å€¼ã€‚
*   `min`å‘Šè¯‰æˆ‘ä»¬è¯¥ç‰¹æ€§çš„æœ€å°å€¼ã€‚
*   `25%`ã€`50%`å’Œ`75%`æ˜¯æ¯ä¸ªç‰¹å¾çš„ç™¾åˆ†ä½æ•°/å››åˆ†ä½æ•°ã€‚è¿™ç§å››åˆ†ä½æ•°ä¿¡æ¯æœ‰åŠ©äºæˆ‘ä»¬å‘ç°å¼‚å¸¸å€¼ã€‚
*   `max`å‘Šè¯‰æˆ‘ä»¬è¯¥ç‰¹æ€§çš„æœ€å¤§å€¼ã€‚

```
dataset.describe()
```

dataset.describe() method output

é‡å‘½ååˆ—ä»¥å¢åŠ å¯è¯»æ€§:

```
dataset.rename(columns = {
    "Col1" : "pelvic_incidence", 
    "Col2" : "pelvic_tilt",
    "Col3" : "lumbar_lordosis_angle",
    "Col4" : "sacral_slope", 
    "Col5" : "pelvic_radius",
    "Col6" : "degree_spondylolisthesis", 
    "Col7" : "pelvic_slope",
    "Col8" : "direct_tilt",
    "Col9" : "thoracic_slope", 
    "Col10" :"cervical_tilt", 
    "Col11" : "sacrum_angle",
    "Col12" : "scoliosis_slope", 
    "Class_att" : "class"}, inplace=True)
```

[DataFrame.info()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html) æ‰“å°å…³äºæ•°æ®å¸§çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬`index` dtype å’Œ`column`dtypeã€`non-null`å€¼å’Œå†…å­˜ä½¿ç”¨æƒ…å†µã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`info()`æ¥çŸ¥é“ä¸€ä¸ªæ•°æ®é›†æ˜¯å¦åŒ…å«ä»»ä½•ç¼ºå¤±å€¼ã€‚

```
dataset.info()
```

## å¯è§†åŒ–å¼‚å¸¸å’Œæ­£å¸¸æƒ…å†µçš„æ•°é‡:

`abnormal`ç—…ä¾‹çš„è¶‹åŠ¿æ¯”`normal`ç—…ä¾‹é«˜ 2 å€ã€‚

```
dataset["class"].value_counts().sort_index().plot.bar()
```

![](img/f2c4246a5ef3f28a0eea381fe8cdcf2b.png)

class distribution

## æ£€æŸ¥åŠŸèƒ½ä¹‹é—´çš„ç›¸å…³æ€§:

[**ç›¸å…³ç³»æ•°**](https://en.wikipedia.org/wiki/Correlation_coefficient) æ˜¯æŸç§ç›¸å…³æ€§çš„æ•°å€¼åº¦é‡ï¼Œè¡¨ç¤ºä¸¤ä¸ªå˜é‡ä¹‹é—´çš„ç»Ÿè®¡å…³ç³»ã€‚

```
dataset.corr()
```

å¯è§†åŒ–ä¸[çƒ­å›¾](https://en.wikipedia.org/wiki/Heat_map)çš„å…³è”:

```
plt.subplots(figsize=(12,8))
sns.heatmap(dataset.corr())
```

![](img/be1fb3a80e30dc3b098ee39cca1283cd.png)

correlation between features

## è‡ªå®šä¹‰ç›¸å…³å›¾:

ä¸€ä¸ª[å¯¹å›¾](https://seaborn.pydata.org/generated/seaborn.pairplot.html)å…è®¸æˆ‘ä»¬çœ‹åˆ°å•ä¸ªå˜é‡çš„åˆ†å¸ƒå’Œä¸¤ä¸ªå˜é‡ä¹‹é—´çš„å…³ç³»ã€‚

```
sns.pairplot(dataset, hue="class")
```

åœ¨ä¸‹å›¾ä¸­ï¼Œå¾ˆå¤šäº‹æƒ…éƒ½åœ¨å‘ç”Ÿã€‚è®©æˆ‘ä»¬è¯•ç€ç†è§£ç»“å¯¹æƒ…èŠ‚ã€‚åœ¨ç»“å¯¹æƒ…èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦éœ€è¦äº†è§£ä¸¤ä»¶äº‹ã€‚ä¸€ä¸ªæ˜¯ç‰¹å¾çš„**åˆ†å¸ƒï¼Œå¦ä¸€ä¸ªæ˜¯ä¸€ä¸ªç‰¹å¾ä¸æ‰€æœ‰å…¶ä»–ç‰¹å¾**ä¹‹é—´çš„**å…³ç³»ã€‚å¦‚æœæˆ‘ä»¬çœ‹å¯¹è§’çº¿ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¯ä¸ªç‰¹å¾çš„åˆ†å¸ƒã€‚è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸‹`first row X first column`ï¼Œè¿™æ¡å¯¹è§’çº¿å‘æˆ‘ä»¬å±•ç¤ºäº†`pelvic_incidence`çš„åˆ†å¸ƒã€‚åŒæ ·ï¼Œå¦‚æœæˆ‘ä»¬è§‚å¯Ÿ`second row X second column`å¯¹è§’çº¿ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°`pelvic_tilt`çš„åˆ†å¸ƒã€‚é™¤å¯¹è§’çº¿ä»¥å¤–çš„æ‰€æœ‰å•å…ƒæ ¼éƒ½æ˜¾ç¤ºäº†ä¸€ä¸ªè¦ç´ ä¸å¦ä¸€ä¸ªè¦ç´ ä¹‹é—´çš„å…³ç³»ã€‚è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸‹`first row X second column`ï¼Œè¿™é‡Œæˆ‘ä»¬å¯ä»¥è¯´æ˜`pelvic_incidence`å’Œ`pelvic_tilt`ä¹‹é—´çš„å…³ç³»ã€‚**

![](img/cd362052ab5eaee9c0308f75ad322fb7.png)

custom correlogram

## ä½¿ç”¨ç›´æ–¹å›¾å¯è§†åŒ–è¦ç´ :

ä¸€ä¸ª[**ç›´æ–¹å›¾**](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html) æ˜¯æ˜¾ç¤ºé¢‘ç‡åˆ†å¸ƒæœ€å¸¸ç”¨çš„å›¾å½¢ã€‚

```
dataset.hist(figsize=(15,12),bins = 20, color="#007959AA")
plt.title("Features Distribution")
plt.show()
```

![](img/e45133d5938dedbd2f7f93c988557b20.png)

features histogram

## æ£€æµ‹å’Œç§»é™¤å¼‚å¸¸å€¼

```
plt.subplots(figsize=(15,6))
dataset.boxplot(patch_artist=True, sym=â€k.â€)
plt.xticks(rotation=90)
```

![](img/62be5f1e0d50a86630a2d386f7339969.png)

Detect outliers using boxplot

**ç§»é™¤å¼‚å¸¸å€¼:**

```
# we use tukey method to remove outliers.
# whiskers are set at 1.5 times Interquartile Range (IQR)def  remove_outlier(feature):
    first_q = np.percentile(X[feature], 25)
    third_q = np.percentile(X[feature], 75)
    IQR = third_q - first_q
    IQR *= 1.5 minimum = first_q - IQR # the acceptable minimum value
    maximum = third_q + IQR # the acceptable maximum value

    mean = X[feature].mean() """
    # any value beyond the acceptance range are considered
    as outliers.    # we replace the outliers with the mean value of that 
      feature.
    """ X.loc[X[feature] < minimum, feature] = mean 
    X.loc[X[feature] > maximum, feature] = mean # taking all the columns except the last one
# last column is the labelX = dataset.iloc[:, :-1]for i in range(len(X.columns)): 
        remove_outlier(X.columns[i])
```

ç§»é™¤å¼‚å¸¸å€¼å:

![](img/e2bfdb890e35b7b25a4e3d8d54f456a7.png)

features distribution after removing outliers

## ç‰¹å¾ç¼©æ”¾:

[ç‰¹å¾ç¼©æ”¾](http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html)å°½ç®¡æ ‡å‡†åŒ–(æˆ– Z åˆ†æ•°å½’ä¸€åŒ–)å¯¹äºè®¸å¤šæœºå™¨å­¦ä¹ ç®—æ³•æ¥è¯´å¯èƒ½æ˜¯ä¸€ä¸ªé‡è¦çš„é¢„å¤„ç†æ­¥éª¤ã€‚æˆ‘ä»¬çš„æ•°æ®é›†åŒ…å«åœ¨é‡çº§ã€å•ä½å’ŒèŒƒå›´ä¸Šå·®å¼‚å¾ˆå¤§çš„è¦ç´ ã€‚ä½†ç”±äºå¤§å¤šæ•°æœºå™¨å­¦ä¹ ç®—æ³•åœ¨è®¡ç®—ä¸­ä½¿ç”¨ä¸¤ä¸ªæ•°æ®ç‚¹ä¹‹é—´çš„æ¬§å‡ é‡Œå¾·è·ç¦»ï¼Œè¿™å°†äº§ç”Ÿä¸€ä¸ªé—®é¢˜ã€‚ä¸ºäº†é¿å…è¿™ç§å½±å“ï¼Œæˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰çš„ç‰¹å¾æ”¾åœ¨ç›¸åŒçš„é‡çº§ä¸Šã€‚è¿™å¯ä»¥é€šè¿‡[ç‰¹å¾ç¼©æ”¾](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e)æ¥å®ç°ã€‚

```
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(X)
scaled_df = pd.DataFrame(data = scaled_data, columns = X.columns)
scaled_df.head()
```

dataset head after feature scaling

## æ ‡ç­¾ç¼–ç :

åƒ [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html) è¿™æ ·çš„ç®—æ³•åªèƒ½å°†æ•°å€¼ä½œä¸ºå®ƒä»¬çš„é¢„æµ‹å˜é‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ç¼–ç æˆ‘ä»¬çš„åˆ†ç±»å€¼ã€‚æ¥è‡ª`sklearn.preprocessing`åŒ…çš„ [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) å¯¹å€¼åœ¨`0`å’Œ`n_classes-1`ä¹‹é—´çš„æ ‡ç­¾è¿›è¡Œç¼–ç ã€‚

```
label = dataset["class"]encoder = LabelEncoder()
label = encoder.fit_transform(label)
```

## æ¨¡å‹åŸ¹è®­å’Œè¯„ä¼°:

```
X = scaled_df
y = labelX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)clf_gnb = GaussianNB()
pred_gnb = clf_gnb.fit(X_train, y_train).predict(X_test)
accuracy_score(pred_gnb, y_test)# Out []: 0.8085106382978723clf_svc = SVC(kernel="linear")
pred_svc = clf_svc.fit(X_train, y_train).predict(X_test)
accuracy_score(pred_svc, y_test)# Out []: 0.7872340425531915clf_xgb =  XGBClassifier()
pred_xgb = clf_xgb.fit(X_train, y_train).predict(X_test)
accuracy_score(pred_xgb, y_test)# Out []: 0.8297872340425532
```

## åŠŸèƒ½é‡è¦æ€§:

```
fig, ax = plt.subplots(figsize=(12, 6))
plot_importance(clf_xgb, ax=ax)
```

![](img/11a99ea04368e4133cb91dc153677e1f.png)

feature importance

## è¾¹ç¼˜åœ°å—

è¾¹é™…å›¾[å…è®¸æˆ‘ä»¬ç ”ç©¶ä¸¤ä¸ªæ•°å­—å˜é‡ä¹‹é—´çš„å…³ç³»ã€‚ä¸­é—´çš„å›¾è¡¨æ˜¾ç¤ºäº†å®ƒä»¬çš„ç›¸å…³æ€§ã€‚](https://python-graph-gallery.com/82-marginal-plot-with-seaborn/)

è®©æˆ‘ä»¬æƒ³è±¡ä¸€ä¸‹`degree_spondylolisthesis`å’Œ`class`ä¹‹é—´çš„å…³ç³»:

```
sns.set(style="white", color_codes=True)
sns.jointplot(x=X["degree_spondylolisthesis"], y=label, kind='kde', color="skyblue")
```

![](img/676d3d3b9c361e448ecc688448d4346f.png)

Marginal plot between `degree_spondylolisthesis and class`

å°±è¿™äº›ã€‚æ„Ÿè°¢é˜…è¯»ã€‚:)

å®Œæ•´ä»£ç è¯·è®¿é—® [Kaggle](https://www.kaggle.com/nasirislamsujan/exploratory-data-analysis-lower-back-pain?scriptVersionId=5480406) æˆ– [Google Colab](https://colab.research.google.com/drive/1m4ZOmii2y9W8YfsWow7wLN3K8Ia84j9Y) ã€‚

å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œç„¶åç»™ğŸ‘é¼“æŒã€‚ç¼–ç å¿«ä¹ï¼