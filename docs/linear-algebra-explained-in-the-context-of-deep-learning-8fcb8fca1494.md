# æ·±åº¦å­¦ä¹ èƒŒæ™¯ä¸‹çš„çº¿æ€§ä»£æ•°è§£é‡Š

> åŸæ–‡ï¼š<https://towardsdatascience.com/linear-algebra-explained-in-the-context-of-deep-learning-8fcb8fca1494?source=collection_archive---------6----------------------->

![](img/2cb23c81bb5de620c2dbd1831963b636.png)

Photo by [Charles Deluvio ğŸ‡µğŸ‡­ğŸ‡¨ğŸ‡¦](https://unsplash.com/@charlesdeluvio?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä½¿ç”¨äº†è‡ªé¡¶å‘ä¸‹çš„æ–¹å¼æ¥è§£é‡Šæ·±åº¦å­¦ä¹ çš„çº¿æ€§ä»£æ•°ã€‚é¦–å…ˆæä¾›åº”ç”¨ç¨‹åºå’Œç”¨é€”ï¼Œç„¶åæ·±å…¥æä¾›æ¦‚å¿µã€‚

ç»´åŸºç™¾ç§‘ä¸­çº¿æ€§ä»£æ•°çš„å®šä¹‰:

> **çº¿æ€§ä»£æ•°**æ˜¯å…³äº**çº¿æ€§**æ–¹ç¨‹å’Œ**çº¿æ€§**å‡½æ•°åŠå…¶é€šè¿‡çŸ©é˜µå’Œå‘é‡ç©ºé—´è¡¨ç¤ºçš„æ•°å­¦åˆ†æ”¯ã€‚

# ç›®å½•:

*   å¼•è¨€ã€‚
*   å‘é‡å’ŒçŸ©é˜µçš„æ•°å­¦è§‚ç‚¹ã€‚
*   çŸ©é˜µçš„ç±»å‹ã€‚
*   çŸ©é˜µåˆ†è§£ã€‚
*   è§„èŒƒã€‚
*   çŸ¢é‡åŒ–ã€‚
*   å¹¿æ’­ã€‚
*   å¤–éƒ¨èµ„æºã€‚

[![](img/6d60b235fcc46a4bd696b90e886419ee.png)](https://www.buymeacoffee.com/laxmanvijay)

[Laxman Vijay (buymeacoffee.com)](https://www.buymeacoffee.com/laxmanvijay)

**ç®€ä»‹:**

å¦‚æœä½ å¼€å§‹å­¦ä¹ æ·±åº¦å­¦ä¹ ï¼Œä½ é¦–å…ˆä¼šæ¥è§¦åˆ°çš„æ˜¯å‰é¦ˆç¥ç»ç½‘ç»œï¼Œè¿™æ˜¯æ·±åº¦å­¦ä¹ ä¸­æœ€ç®€å•ä¹Ÿæ˜¯æœ€æœ‰ç”¨çš„ç½‘ç»œã€‚åœ¨å¼•æ“ç›–ä¸‹ï¼Œå‰é¦ˆç¥ç»ç½‘ç»œåªæ˜¯ä¸€ä¸ªå¤åˆå‡½æ•°ï¼Œå°†ä¸€äº›çŸ©é˜µå’Œå‘é‡ç›¸ä¹˜ã€‚

è¿™å¹¶ä¸æ˜¯è¯´å‘é‡å’ŒçŸ©é˜µæ˜¯è¿›è¡Œè¿™äº›è¿ç®—çš„å”¯ä¸€æ–¹æ³•ï¼Œä½†æ˜¯å¦‚æœä½ è¿™æ ·åšï¼Œå®ƒä»¬ä¼šå˜å¾—éå¸¸é«˜æ•ˆã€‚

![](img/85fc627a7050abc6d013df1864957db9.png)

ä¸Šå›¾æ˜¾ç¤ºäº†ä¸€ä¸ªç®€å•çš„å‘å‰ä¼ æ’­ä¿¡æ¯çš„å‰é¦ˆç¥ç»ç½‘ç»œã€‚

è¯¥å›¾åƒæ˜¯ç¥ç»ç½‘ç»œçš„æ¼‚äº®è¡¨ç¤ºï¼Œä½†æ˜¯è®¡ç®—æœºå¦‚ä½•ç†è§£è¿™ä¸€ç‚¹ã€‚åœ¨è®¡ç®—æœºä¸­ï¼Œç¥ç»ç½‘ç»œçš„å„å±‚ç”¨å‘é‡è¡¨ç¤ºã€‚å°†è¾“å…¥å±‚è§†ä¸º Xï¼Œå°†éšè—å±‚è§†ä¸º hã€‚ç°åœ¨ä¸è€ƒè™‘è¾“å‡ºå±‚ã€‚(è¿™é‡Œä¸æ¶‰åŠå‰é¦ˆç¥ç»ç½‘ç»œçš„è®¡ç®—è¿‡ç¨‹ã€‚)

æ‰€ä»¥ï¼Œå®ƒå¯ä»¥ç”¨å‘é‡å’ŒçŸ©é˜µæ¥è¡¨ç¤ºï¼Œ

![](img/ccdb41f911d6a24bb29b13135517ac70.png)

ä¸Šå›¾æ˜¾ç¤ºäº†è®¡ç®—ä¸Šè¿°ç¥ç»ç½‘ç»œçš„ç¬¬ä¸€ä¸ªä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ªéšè—å±‚çš„è¾“å‡ºæ‰€éœ€çš„æ“ä½œ(æœªæ˜¾ç¤ºè¾“å‡ºå±‚çš„è®¡ç®—)ã€‚æˆ‘ä»¬æ¥åˆ†è§£ä¸€ä¸‹ã€‚

ç½‘ç»œçš„æ¯ä¸€åˆ—éƒ½æ˜¯å‘é‡ã€‚å‘é‡æ˜¯æ•°æ®(æˆ–ç‰¹å¾)é›†åˆçš„åŠ¨æ€æ•°ç»„ã€‚åœ¨å½“å‰çš„ç¥ç»ç½‘ç»œä¸­ï¼Œå‘é‡' **x** 'ä¿å­˜è¾“å…¥ã€‚å°†è¾“å…¥è¡¨ç¤ºä¸ºå‘é‡å¹¶ä¸æ˜¯å¼ºåˆ¶æ€§çš„ï¼Œä½†æ˜¯å¦‚æœä½ è¿™æ ·åšï¼Œå®ƒä»¬ä¼šå˜å¾—è¶Šæ¥è¶Šä¾¿äºå¹¶è¡Œæ‰§è¡Œæ“ä½œã€‚

æ·±åº¦å­¦ä¹ ï¼Œå…·ä½“æ¥è¯´ï¼Œç¥ç»ç½‘ç»œçš„è®¡ç®—æˆæœ¬å¾ˆé«˜ï¼Œæ‰€ä»¥å®ƒä»¬éœ€è¦è¿™ä¸ªå¥½æŠ€å·§æ¥åŠ å¿«è®¡ç®—é€Ÿåº¦ã€‚

**è¿™å«çŸ¢é‡åŒ–ã€‚å®ƒä»¬ä½¿å¾—è®¡ç®—é€Ÿåº¦æå¿«ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ·±åº¦å­¦ä¹ éœ€è¦ GPU çš„ä¸»è¦åŸå› ä¹‹ä¸€**[](https://www.analyticsvidhya.com/blog/2017/05/gpus-necessary-for-deep-learning/)***ï¼Œå› ä¸ºå®ƒä»¬æ“…é•¿çŸ©é˜µä¹˜æ³•ä¹‹ç±»çš„çŸ¢é‡åŒ–è¿ç®—ã€‚(æˆ‘ä»¬å°†åœ¨æœ€åæ·±å…¥äº†è§£è¿™ä¸€ç‚¹)ã€‚***

*éšè—å±‚ H çš„è¾“å‡ºé€šè¿‡æ‰§è¡Œ **H = f( *W* æ¥è®¡ç®—ã€‚x + b)ã€‚***

*è¿™é‡Œ W ç§°ä¸ºæƒé‡çŸ©é˜µï¼Œb ç§°ä¸ºåå·®ï¼Œf æ˜¯æ¿€æ´»å‡½æ•°ã€‚(æœ¬æ–‡ä¸è§£é‡Šå…³äºå‰é¦ˆç¥ç»ç½‘ç»œï¼Œå¦‚æœä½ éœ€è¦ä¸€æœ¬å…³äº FFNN æ¦‚å¿µçš„åˆçº§è¯»æœ¬ï¼Œ[çœ‹è¿™é‡Œ](/deep-learning-feedforward-neural-network-26a6705dbdc7)ã€‚)*

*è®©æˆ‘ä»¬åˆ†è§£è¿™ä¸ªç­‰å¼ï¼Œ*

*ç¬¬ä¸€ä¸ªç»„ä»¶æ˜¯ ***W*** ã€‚**xï¼›è¿™æ˜¯ä¸€ä¸ª**çŸ©é˜µ-å‘é‡ä¹˜ç§¯ï¼Œ**å› ä¸º W æ˜¯çŸ©é˜µï¼Œ ***x*** æ˜¯å‘é‡ã€‚åœ¨å¼€å§‹ä¹˜æ³•è¿ç®—ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆäº†è§£ä¸€ä¸‹ç¬¦å·:*é€šå¸¸å‘é‡ç”¨å°ç²—æ–œä½“å­—æ¯è¡¨ç¤º(å¦‚* ***x*** *)ï¼ŒçŸ©é˜µç”¨å¤§å†™ç²—æ–œä½“å­—æ¯è¡¨ç¤º(å¦‚* ***X*** *)ã€‚å¦‚æœå­—æ¯æ˜¯å¤§å†™åŠ ç²—ä½†ä¸æ˜¯æ–œä½“ï¼Œé‚£ä¹ˆå®ƒæ˜¯ä¸€ä¸ªå¼ é‡(å¦‚* **X** *)ã€‚****

*ä»è®¡ç®—æœºç§‘å­¦çš„è§’åº¦æ¥çœ‹*

*æ ‡é‡:å•ä¸ªæ•°å­—ã€‚*

*Vector:å€¼çš„åˆ—è¡¨ã€‚(ç§© 1 å¼ é‡)*

*çŸ©é˜µ:äºŒç»´å€¼åˆ—è¡¨ã€‚(ç§© 2 å¼ é‡)*

*å¼ é‡:ç§©ä¸º n çš„å¤šç»´çŸ©é˜µã€‚*

***å‘ä¸‹é’»å–:***

*![](img/54b5f0bd130b1071079b14cb76443b8d.png)*

***ä»æ•°å­¦çš„è§’åº¦:***

***çŸ¢é‡:***

*çŸ¢é‡æ˜¯æ—¢æœ‰å¤§å°åˆæœ‰æ–¹å‘çš„é‡ã€‚å®ƒæ˜¯ä¸€ä¸ªå­˜åœ¨äºç©ºé—´çš„å®ä½“ï¼Œå¦‚æœå®ƒæ˜¯ä¸€ä¸ªå­˜åœ¨äºçœŸå®ç©ºé—´çš„äºŒç»´å‘é‡ï¼Œå®ƒçš„å­˜åœ¨ç”¨ ***xâˆˆ â„*** *è¡¨ç¤ºã€‚(æ¯ä¸ªå…ƒç´ è¡¨ç¤ºæ²¿ä¸åŒè½´çš„åæ ‡ã€‚)**

*![](img/8370121a156925212190bf32296347fb.png)*

*red and blue color vectors are the basis vectors.*

*2D ç©ºé—´ä¸­çš„æ‰€æœ‰å‘é‡éƒ½å¯ä»¥é€šè¿‡ç§°ä¸º**åŸºå‘é‡**çš„ä¸¤ä¸ªå‘é‡çš„çº¿æ€§ç»„åˆæ¥è·å¾—ã€‚(ç”¨ I å’Œ j è¡¨ç¤º)(ä¸€èˆ¬æ¥è¯´ï¼ŒN ç»´çš„å‘é‡å¯ä»¥ç”¨ N ä¸ªåŸºå‘é‡æ¥è¡¨ç¤ºã€‚)å®ƒä»¬æ˜¯**å•ä½æ³•å‘é‡ï¼Œå› ä¸ºå®ƒä»¬çš„å¤§å°æ˜¯ 1ï¼Œå¹¶ä¸”å®ƒä»¬å½¼æ­¤å‚ç›´**ã€‚è¿™ä¸¤ä¸ªå‘é‡ä¸­çš„ä¸€ä¸ªä¸èƒ½ç”¨å¦ä¸€ä¸ªå‘é‡æ¥è¡¨ç¤ºã€‚æ‰€ä»¥å®ƒä»¬è¢«ç§°ä¸º**çº¿æ€§æ— å…³çŸ¢é‡**ã€‚(å¦‚æœä»»ä½•ä¸€ä¸ªå‘é‡ä¸èƒ½ç”±ä¸€ç»„å‘é‡çš„çº¿æ€§ç»„åˆå¾—åˆ°ï¼Œé‚£ä¹ˆè¿™ä¸ªå‘é‡ä¸é‚£ä¸ªé›†åˆçº¿æ€§æ— å…³)ã€‚å¯ä»¥é€šè¿‡è¿™ä¸¤ä¸ªå‘é‡çš„çº¿æ€§ç»„åˆè·å¾—çš„ 2D ç©ºé—´ä¸­çš„æ‰€æœ‰ç‚¹é›†è¢«ç§°ä¸ºè¿™äº›å‘é‡çš„**è·¨åº¦**ã€‚å¦‚æœä¸€ä¸ªå‘é‡ç”±ä¸€ç»„å…¶ä»–å‘é‡çš„çº¿æ€§ç»„åˆ(åŠ æ³•ã€ä¹˜æ³•)æ¥è¡¨ç¤ºï¼Œé‚£ä¹ˆå®ƒ**çº¿æ€§ä¾èµ–äºè¯¥ç»„å‘é‡**ã€‚(å°†è¿™ä¸ªæ–°å‘é‡æ·»åŠ åˆ°ç°æœ‰é›†åˆä¸­æ˜¯æ²¡æœ‰ç”¨çš„ã€‚)*

*ä»»ä½•ä¸¤ä¸ªçŸ¢é‡éƒ½å¯ä»¥ç›¸åŠ ã€‚å®ƒä»¬å¯ä»¥ç›¸ä¹˜ã€‚å®ƒä»¬çš„ä¹˜æ³•æœ‰ä¸¤ç§ç±»å‹ï¼Œç‚¹ç§¯å’Œå‰ç§¯ã€‚[å‚è€ƒæ­¤å¤„ã€‚](https://ltcconline.net/greenl/courses/107/vectors/dotcros.htm)*

***çŸ©é˜µ:***

*çŸ©é˜µæ˜¯æ•°å­—çš„ 2D é˜µåˆ—ã€‚å®ƒä»¬ä»£è¡¨**è½¬æ¢**ã€‚2 * 2 çŸ©é˜µçš„æ¯ä¸€åˆ—è¡¨ç¤ºåœ¨ 2D ç©ºé—´è¢«åº”ç”¨è¯¥å˜æ¢ä¹‹åçš„ 2 ä¸ªåŸºæœ¬å‘é‡ä¸­çš„æ¯ä¸€ä¸ªã€‚å®ƒä»¬çš„ç©ºé—´è¡¨ç¤ºæ˜¯ ***W âˆˆ â„ *æœ‰ 3 è¡Œ 2 åˆ—ã€‚****

***ä¸€ä¸ªçŸ©é˜µçš„å‘é‡ç§¯å«åšé‚£ä¸ªå‘é‡çš„å˜æ¢ï¼Œè€Œä¸€ä¸ªçŸ©é˜µçš„çŸ©é˜µç§¯å«åšå˜æ¢çš„åˆæˆã€‚***

*åªæœ‰ä¸€ä¸ªçŸ©é˜µä¸å¯¹å‘é‡åšä»»ä½•å˜æ¢ã€‚å°±æ˜¯å•ä½çŸ©é˜µ( ***I*** )ã€‚****I åˆ—ä»£è¡¨åŸºçŸ¢ã€‚*****

****çŸ©é˜µçš„è¡Œåˆ—å¼***ç”¨ det(*)è¡¨ç¤ºçŸ©é˜µæ‰€æè¿°çš„çº¿æ€§å˜æ¢çš„æ¯”ä¾‹å› å­ã€‚****

*****ä¸ºä»€ä¹ˆæ•°å­¦è§†è§’å¯¹æ·±åº¦å­¦ä¹ ç ”ç©¶è€…å¾ˆé‡è¦ï¼Ÿå› ä¸ºå®ƒä»¬å¸®åŠ©æˆ‘ä»¬ç†è§£åŸºæœ¬å¯¹è±¡çš„åŸºæœ¬è®¾è®¡æ¦‚å¿µã€‚ä»–ä»¬ä¹Ÿå¸®åŠ©è®¾è®¡æ·±åº¦å­¦ä¹ é—®é¢˜çš„åˆ›é€ æ€§è§£å†³æ–¹æ¡ˆã€‚ä½†æ˜¯ä¸ç”¨æ‹…å¿ƒï¼Œæœ‰å¾ˆå¤šè¯­è¨€å’Œè½¯ä»¶åŒ…ä¸ºæˆ‘ä»¬åšè¿™äº›å®ç°ã€‚ä½†æ˜¯çŸ¥é“å®ƒä»¬çš„å®ç°ä¹Ÿå¾ˆå¥½ã€‚*****

***python ç¼–ç¨‹è¯­è¨€çš„ numpy å°±æ˜¯è¿™æ ·ä¸€ä¸ªåº“ã€‚***

***![](img/f09d8c86fa4e376dd887e2b7544d883d.png)***

***æœ‰å¾ˆå¤šå­¦ä¹ æ•°å­—çš„èµ„æºã€‚(è¿™å¯¹å­¦ä¹ æ·±åº¦å­¦ä¹ å¾ˆé‡è¦ï¼Œå¦‚æœç”¨ python çš„è¯ã€‚)[çœ‹è¿™é‡Œ](https://docs.scipy.org/doc/numpy-1.15.0/user/basics.html)ã€‚***

****åœ¨è¿™é‡Œï¼Œnp.array åˆ›å»ºäº†ä¸€ä¸ª numpy æ•°ç»„ã€‚****

***np.random æ˜¯ä¸€ä¸ªåŒ…å«éšæœºæ•°ç”Ÿæˆæ–¹æ³•çš„åŒ…ã€‚***

***ç‚¹æ³•æ˜¯è®¡ç®—çŸ©é˜µé—´ä¹˜ç§¯çš„æ–¹æ³•ã€‚***

***æˆ‘ä»¬å¯ä»¥æ”¹å˜ numpy æ•°ç»„çš„å½¢çŠ¶å¹¶æ£€æŸ¥å®ƒã€‚***

***è¿™é‡Œå¯ä»¥çœ‹åˆ°ï¼ŒW.x çš„ä¹˜ç§¯æ˜¯ä¸€ä¸ªçŸ¢é‡ï¼ŒåŠ ä¸Š bï¼Œb æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚è¿™ä¼šè‡ªåŠ¨å°† b æ‰©å±•ä¸ºè½¬ç½®([1ï¼Œ1])ã€‚* ***è¿™ç§ b åˆ°å‡ ä¸ªä½ç½®çš„éšå¼å¤åˆ¶ç§°ä¸ºå¹¿æ’­ã€‚(ä¸€ä¼šå„¿æˆ‘ä»¬ä¼šæ·±å…¥äº†è§£ã€‚)*****

***ä½ æ³¨æ„åˆ°è½¬ç½®è¿™ä¸ªè¯äº†å—:* ***ä¸€ä¸ªçŸ©é˜µçš„è½¬ç½®æ˜¯çŸ©é˜µçš„é•œåƒè·¨è¿‡å¯¹è§’çº¿(ä»çŸ©é˜µçš„å·¦ä¸Šåˆ°å³ä¸‹ã€‚*)****

```
**## numpy code for transpose
import numpy as np
A = np.array([[1,2],
              [3,4],
              [5,6]])
B = np.transpose(A) 
##or
B = A.T**
```

****çŸ©é˜µç±»å‹:****

****å¯¹è§’çŸ©é˜µ**:é™¤ä¸»å¯¹è§’å…ƒç´ å¤–ï¼Œæ‰€æœ‰å…ƒç´ ä¸ºé›¶ã€‚**

**![](img/7feb405935371b3fc6751c013b2014b7.png)**

**diagonal matrix**

****å•ä½çŸ©é˜µ**:å¯¹è§’å€¼ä¸º 1 çš„å¯¹è§’çŸ©é˜µã€‚**

**![](img/fe04a540af6bbf63245f641650ebb69a.png)**

**identity matrix**

```
**## numpy code to create identity matrix
import numpy as np
a = np.eye(4)**
```

**å¯¹ç§°çŸ©é˜µ:ä¸å…¶è½¬ç½®çŸ©é˜µç›¸ç­‰çš„çŸ©é˜µã€‚A =è½¬ç½®(A)**

****å¥‡å¼‚çŸ©é˜µ**:è¡Œåˆ—å¼ä¸ºé›¶ï¼Œåˆ—çº¿æ€§ç›¸å…³çš„çŸ©é˜µã€‚å®ƒä»¬çš„ç§©å°äºçŸ©é˜µçš„è¡Œæ•°æˆ–åˆ—æ•°ã€‚**

****çŸ©é˜µåˆ†è§£:****

****çŸ©é˜µåˆ†è§£**æˆ–**çŸ©é˜µåˆ†è§£**æ˜¯å°†çŸ©é˜µåˆ†è§£æˆçŸ©é˜µçš„ä¹˜ç§¯ã€‚æœ‰è®¸å¤šä¸åŒçš„çŸ©é˜µåˆ†è§£ï¼›æ¯ä¸€ç§éƒ½åœ¨ä¸€ç±»ç‰¹å®šçš„é—®é¢˜ä¸­æ‰¾åˆ°ç”¨é€”ã€‚æœ€å¹¿æ³›ä½¿ç”¨çš„ä¸€ç§çŸ©é˜µåˆ†è§£å«åš**ç‰¹å¾åˆ†è§£**ï¼Œæˆ‘ä»¬å°†çŸ©é˜µåˆ†è§£æˆä¸€ç»„ç‰¹å¾å‘é‡å’Œç‰¹å¾å€¼ã€‚**

**æ–¹é˜µçš„æœ¬å¾å‘é‡*æ˜¯éé›¶å‘é‡*ä½¿å¾—ä¹˜ä»¥*ä»…æ”¹å˜*çš„æ¯”ä¾‹******

******A . v***=Î»ã€‚ ***v******

**è¿™é‡Œ ***v*** æ˜¯æœ¬å¾å‘é‡ï¼ŒÎ»æ˜¯æœ¬å¾å€¼ã€‚**

```
**## numpy program to find eigen vectors.

from numpy import array
from numpy.linalg import eig
# define matrix
A = array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(A)
# calculate eigendecomposition
values, vectors = eig(A)
print(values)
print(vectors)**
```

**![](img/8a4be0b11c070686194125d053c776c4.png)**

**ç‰¹å¾åˆ†è§£åœ¨æœºå™¨å­¦ä¹ ä¸­éå¸¸æœ‰ç”¨ã€‚è¿™å¯¹äºé™ç»´è¿™æ ·çš„æ¦‚å¿µç‰¹åˆ«æœ‰ç”¨ã€‚**

**æœ‰å…³ç‰¹å¾åˆ†è§£çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒæ·±åº¦å­¦ä¹ ä¹¦ç±[ç¬¬ 2 ç« ](http://www.deeplearningbook.org/contents/linear_algebra.html)**

**æ·±åº¦å­¦ä¹ ä¸­è¿˜ä¼šç”¨åˆ°å…¶ä»–å‡ ç§çŸ©é˜µåˆ†è§£æŠ€æœ¯ã€‚[çœ‹è¿™é‡Œã€‚](https://heartbeat.fritz.ai/applications-of-matrix-decompositions-for-machine-learning-f1986d03571a)**

****è§„èŒƒ:****

****è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ:****

**å½“ä½ å‚åŠ æ·±åº¦å­¦ä¹ è®²åº§æ—¶ï¼Œä½ ç»å¸¸ä¼šå¬åˆ°è¿‡åº¦é€‚åº”å’Œæ¬ é€‚åº”è¿™ä¸ªæœ¯è¯­ã€‚è¿™äº›æœ¯è¯­æè¿°äº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å‡†ç¡®æ€§çŠ¶æ€ã€‚**

**![](img/a509007d016bf2b89701f01e43748e90.png)**

**This image is the best explanation of overfitting and underfitting.**

**è¿‡æ‹Ÿåˆæ˜¯æŒ‡æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®å­¦ä¹ å¾—å¤ªå¥½ã€‚å®ƒçœŸçš„çªƒå–äº†è®­ç»ƒæ•°æ®ã€‚åœ¨è¿‡æ‹Ÿåˆæ¨¡å‹ä¸­ï¼Œè®­ç»ƒç²¾åº¦éå¸¸é«˜ï¼ŒéªŒè¯ç²¾åº¦éå¸¸ä½ã€‚**

**æ¬ æ‹Ÿåˆæ¨¡å‹æ— æ³•å­¦ä¹ è®­ç»ƒæ•°æ®ã€‚åœ¨æ¬ æ‹Ÿåˆæ¨¡å‹ä¸­ï¼Œè®­ç»ƒå’ŒéªŒè¯ç²¾åº¦éƒ½éå¸¸ä½ã€‚**

**è¿‡åº¦æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆéƒ½ä¼šå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ä½³ã€‚ä½†åˆ°ç›®å‰ä¸ºæ­¢ï¼Œåº”ç”¨æœºå™¨å­¦ä¹ ä¸­æœ€å¸¸è§çš„é—®é¢˜æ˜¯è¿‡åº¦æ‹Ÿåˆã€‚**

**ä¸ºäº†å‡å°‘è¿‡åº¦æ‹Ÿåˆï¼Œæˆ‘ä»¬å¿…é¡»ä½¿ç”¨ä¸€ç§å«åš**æ­£åˆ™åŒ–çš„æŠ€æœ¯ã€‚*é˜²æ­¢å¯¹è®­ç»ƒæ•°æ®çš„å¼ºè®°ï¼Œä»è€Œé¿å…è¿‡æ‹Ÿåˆçš„é£é™©ã€‚*****

**æ·±åº¦å­¦ä¹ å·¥ç¨‹å¸ˆçš„**æœ€é‡è¦çš„èŒè´£**æ˜¯åˆ›å»ºä¸€ä¸ªé€šå¸¸é€‚åˆè¾“å…¥çš„æ¨¡å‹ã€‚æ­£åˆ™åŒ–æœ‰å‡ ç§æ–¹æ³•ã€‚æœ€è‘—åçš„æ˜¯ **L1 æ­£åˆ™åŒ–(Lasso)å’Œ L2 æ­£åˆ™åŒ–(Ridge)ã€‚****

**æ²¡æœ‰æä¾›è¿™äº›çš„ç»†èŠ‚ï¼Œä½†æ˜¯è¦ç†è§£è¿™äº›ï¼Œä½ å¿…é¡»çŸ¥é“ä»€ä¹ˆæ˜¯è§„èŒƒã€‚**

****å®šé¢:****

**èŒƒæ•°æ˜¯å‘é‡çš„å¤§å°ã€‚å‘é‡ ***x*** çš„èŒƒæ•°çš„ä¸€èˆ¬å…¬å¼ä¸º:**

**![](img/c23fe251b2846b038f0b8122bc0b0b93.png)**

**p=2 çš„ **L èŒƒæ•°**ç§°ä¸ºæ¬§å‡ é‡Œå¾·èŒƒæ•°ï¼Œå› ä¸ºå®ƒæ˜¯åŸç‚¹å’Œ ***x.*** ä¹‹é—´çš„æ¬§å‡ é‡Œå¾·è·ç¦»**

****L èŒƒæ•°**å°±æ˜¯å‘é‡æ‰€æœ‰å…ƒç´ çš„å’Œã€‚å½“ç³»ç»Ÿéœ€è¦æ›´é«˜çš„ç²¾åº¦æ—¶ï¼Œå®ƒç”¨äºæœºå™¨å­¦ä¹ ã€‚æ¸…æ¥šåœ°åŒºåˆ†é›¶å…ƒç´ å’Œéé›¶å…ƒç´ ã€‚L èŒƒæ•°ä¹Ÿè¢«ç§°ä¸º**æ›¼å“ˆé¡¿èŒƒæ•°**ã€‚**

**è¿˜æœ‰**æœ€å¤§èŒƒæ•°ï¼Œ**æ˜¯é‡å€¼æœ€å¤§çš„å…ƒç´ çš„ç»å¯¹å€¼ã€‚**

**çŸ©é˜µçš„ L èŒƒæ•°ç­‰ä»·äº **frobenius èŒƒæ•°ã€‚****

**![](img/5272777b1af13263b1990d8bb7c3a081.png)**

**frobenius norm.**

**ä¸ä»…åœ¨æ­£åˆ™åŒ–ï¼Œè§„èŒƒä¹Ÿç”¨äºä¼˜åŒ–ç¨‹åºã€‚**

**å¥½äº†ï¼Œç°åœ¨åœ¨æ‰€æœ‰è¿™äº›æ¦‚å¿µå’Œç†è®ºä¹‹åï¼Œæˆ‘ä»¬å¼€å§‹æ¶µç›–æ·±åº¦å­¦ä¹ æ‰€éœ€çš„æœ€é‡è¦çš„éƒ¨åˆ†ã€‚å®ƒä»¬æ˜¯å‘é‡åŒ–å’Œå¹¿æ’­ã€‚**

# ****çŸ¢é‡åŒ–:****

**è¿™æ˜¯å‡å°‘å¾ªç¯æ‰§è¡Œçš„æŠ€å·§ï¼Œé€šè¿‡æä¾›å‘é‡å½¢å¼çš„æ•°æ®ä½¿è¿›ç¨‹å¹¶è¡Œæ‰§è¡Œã€‚**

**è®¸å¤š CPU éƒ½æœ‰â€œå‘é‡â€æˆ–â€œSIMDâ€(å•æŒ‡ä»¤å¤šæ•°æ®)æŒ‡ä»¤é›†ï¼Œè¿™äº›æŒ‡ä»¤é›†åŒæ—¶å¯¹ä¸¤ä¸ªã€å››ä¸ªæˆ–æ›´å¤šä¸ªæ•°æ®åº”ç”¨ç›¸åŒçš„æ“ä½œã€‚20 ä¸–çºª 90 å¹´ä»£åˆï¼ŒSIMD åœ¨é€šç”¨ CPU ä¸Šå¼€å§‹æµè¡Œã€‚**

**æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[å¼—æ—çš„åˆ†ç±»ã€‚](https://en.wikipedia.org/wiki/Flynn%27s_taxonomy)**

**![](img/41bb793b231152bb6e8457dc76cdb557.png)**

**å‘é‡åŒ–æ˜¯é‡å†™ä¸€ä¸ªå¾ªç¯çš„è¿‡ç¨‹ï¼Œå®ƒä¸æ˜¯å¤„ç†æ•°ç»„ä¸­çš„ä¸€ä¸ªå…ƒç´  N æ¬¡ï¼Œè€Œæ˜¯åŒæ—¶å¤„ç†(æ¯”å¦‚è¯´)æ•°ç»„ä¸­çš„ 4 ä¸ªå…ƒç´  N/4 æ¬¡ã€‚**

**Numpy åœ¨ä»–ä»¬çš„ç®—æ³•ä¸­å¤§é‡å®ç°äº†çŸ¢é‡åŒ–ã€‚è¿™æ˜¯ numpy çš„å®˜æ–¹å£°æ˜ã€‚**

> **çŸ¢é‡åŒ–æè¿°äº†æ²¡æœ‰ä»»ä½•æ˜¾å¼å¾ªç¯ã€ç´¢å¼•ç­‰ã€‚ï¼Œåœ¨ä»£ç ä¸­â€”â€”å½“ç„¶ï¼Œè¿™äº›äº‹æƒ…åªæ˜¯åœ¨ä¼˜åŒ–ã€é¢„ç¼–è¯‘ C ä»£ç çš„â€œå¹•åâ€å‘ç”Ÿã€‚çŸ¢é‡åŒ–ä»£ç æœ‰è®¸å¤šä¼˜ç‚¹ï¼Œå…¶ä¸­åŒ…æ‹¬:**
> 
> **çŸ¢é‡åŒ–ä»£ç æ›´åŠ ç®€æ´ï¼Œä¹Ÿæ›´å®¹æ˜“é˜…è¯»**
> 
> **æ›´å°‘çš„ä»£ç è¡Œé€šå¸¸æ„å‘³ç€æ›´å°‘çš„é”™è¯¯**
> 
> **ä»£ç æ›´ç±»ä¼¼äºæ ‡å‡†çš„æ•°å­¦ç¬¦å·(é€šå¸¸æ›´å®¹æ˜“æ­£ç¡®åœ°ç¼–å†™æ•°å­¦ç»“æ„)**
> 
> **çŸ¢é‡åŒ–ä¼šäº§ç”Ÿæ›´å¤šâ€œPythonic å¼â€ä»£ç ã€‚å¦‚æœæ²¡æœ‰å‘é‡åŒ–ï¼Œæˆ‘ä»¬çš„ä»£ç å°†å……æ–¥ç€ä½æ•ˆå’Œéš¾ä»¥é˜…è¯»çš„å¾ªç¯ã€‚**

****ä»£ç ç¤ºä¾‹:****

```
**## to add two arrays together.## consider two basic python lists.
a = [1,2,3,4,5]
b = [2,3,4,5,6]
c = []## without vectorization.for i in range(len(a)): 
    c.append(a[i]+b[i])## using vectorization.a = np.array([1,2,3,4,5])
b = np.array([2,3,4,5,6])
c = a+b**
```

**ä¸Šé¢çš„ä»£ç ç¤ºä¾‹æ˜¯ä¸€ä¸ªè¿‡äºç®€åŒ–çš„çŸ¢é‡åŒ–ç¤ºä¾‹ã€‚è€Œ**å½“è¾“å…¥æ•°æ®å˜å¤§æ—¶ï¼ŒçŸ¢é‡åŒ–æ‰çœŸæ­£å‘æŒ¥ä½œç”¨ã€‚****

**å…³äºçŸ¢é‡åŒ–çš„æ›´å¤šç»†èŠ‚ï¼Œè¯·çœ‹è¿™é‡Œã€‚**

# **å¹¿æ’­:**

**ä¸‹ä¸€ä¸ªé‡è¦çš„æ¦‚å¿µæ˜¯å¹¿æ’­ã€‚æ°ç‘ç±³Â·éœåå¾·çˆµå£«åœ¨ä»–çš„ä¸€æ¬¡æœºå™¨å­¦ä¹ è®²åº§ä¸­è¯´ï¼Œå¹¿æ’­å¯èƒ½æ˜¯æœºå™¨å­¦ä¹ ç¨‹åºå‘˜æœ€é‡è¦çš„å·¥å…·å’ŒæŠ€èƒ½ã€‚**

**æ¥è‡ª [Numpy æ–‡æ¡£](https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html):**

```
**The term broadcasting describes how numpy treats arrays with 
different shapes during arithmetic operations. Subject to certain 
constraints, the smaller array is â€œbroadcastâ€ across the larger 
array so that they have compatible shapes. Broadcasting provides a 
means of vectorizing array operations so that looping occurs in C
instead of Python. It does this without making needless copies of 
data and usually leads to efficient algorithm implementations.**
```

**![](img/150c1e8f434b2991ed0bbdabcbdcb7e5.png)**

**ä»£ç ç¤ºä¾‹:**

```
**a = np.array([1.0, 2.0, 3.0])
b = 2.0
 a * b
 array([ 2.,  4.,  6.])this is similar toa = np.array([1.0, 2.0, 3.0])
b = np.array([2.0, 2.0, 2.0])
a * b
array([ 2.,  4.,  6.])**
```

**æ•°ç»„ b è¢«æ‰©å±•ï¼Œä»è€Œå¯ä»¥åº”ç”¨ç®—æœ¯è¿ç®—ã€‚**

**å¹¿æ’­ä¸æ˜¯ä¸€ä¸ªæ–°æ¦‚å¿µã€‚è¿™æ˜¯ä¸€ä¸ªç›¸å¯¹å¤è€çš„å·¥å…·ï¼Œå¯ä»¥è¿½æº¯åˆ° 50 å¹´ä»£ã€‚åœ¨ä»–çš„è®ºæ–‡ [" **ç¬¦å·ä½œä¸ºæ€ç»´å·¥å…·** "](http://www.eecg.toronto.edu/~jzhu/csc326/readings/iverson.pdf) ï¼Œ[ä¸­ï¼ŒKenneth Iverson](https://en.wikipedia.org/wiki/Kenneth_E._Iverson) æè¿°äº†å‡ ç§æ•°å­¦ä½¿ç”¨å·¥å…·ï¼Œè¿™äº›å·¥å…·å…è®¸æˆ‘ä»¬ä»¥æ–°çš„è§†è§’æ€è€ƒã€‚ä»–ç¬¬ä¸€æ¬¡æåˆ°å¹¿æ’­ä¸æ˜¯ä½œä¸ºä¸€ç§è®¡ç®—æœºç®—æ³•ï¼Œè€Œæ˜¯ä½œä¸ºä¸€ç§æ•°å­¦è¿‡ç¨‹ã€‚ä»–åœ¨ä¸€ä¸ªåä¸º [APL](https://en.wikipedia.org/wiki/APL_(programming_language)) çš„è½¯ä»¶ä¸­å®ç°äº†è®¸å¤šè¿™æ ·çš„å·¥å…·ã€‚**

**ä»–çš„å„¿å­åæ¥æ‰©å±•äº†ä»–çš„æƒ³æ³•ï¼Œç»§ç»­åˆ›é€ äº†å¦ä¸€ä¸ªè½¯ä»¶ï¼Œå«åš J è½¯ä»¶ã€‚è¿™ä¸€å§¿æ€æ„å‘³ç€ï¼Œé€šè¿‡è½¯ä»¶ï¼Œæˆ‘ä»¬å¾—åˆ°çš„æ˜¯è¶…è¿‡ 50 å¹´çš„æ·±å…¥ç ”ç©¶ï¼Œåˆ©ç”¨è¿™äº›ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸€å°æ®µä»£ç ä¸­å®ç°éå¸¸å¤æ‚çš„æ•°å­¦å‡½æ•°ã€‚**

**åŒæ ·éå¸¸æ–¹ä¾¿çš„æ˜¯ï¼Œè¿™äº›ç ”ç©¶ä¹Ÿåœ¨æˆ‘ä»¬ä»Šå¤©ä½¿ç”¨çš„è¯­è¨€ä¸­æ‰¾åˆ°äº†è‡ªå·±çš„æ–¹å¼ï¼Œæ¯”å¦‚ python å’Œ numpyã€‚**

**æ‰€ä»¥è¯·è®°ä½ï¼Œè¿™äº›ä¸æ˜¯ä¸€å¤œä¹‹é—´äº§ç”Ÿçš„ç®€å•æƒ³æ³•ã€‚è¿™äº›å°±åƒæ˜¯æ€è€ƒæ•°å­¦åŠå…¶è½¯ä»¶å®ç°çš„åŸºæœ¬æ–¹æ³•ã€‚(ä»¥ä¸Šå†…å®¹æ‘˜è‡ª fast.ai æœºå™¨å­¦ä¹ è¯¾ç¨‹ã€‚)**

**å…³äº numpy ç‰ˆæœ¬å¹¿æ’­çš„æ›´å¤šç»†èŠ‚ï¼Œ[çœ‹è¿™é‡Œ](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)ã€‚**

**å¥½äº†ï¼Œè¿™å°±å¤Ÿäº†ï¼Œè¿™ç¯‡æ–‡ç« å‘åˆå­¦è€…ä»‹ç»äº†è®¸å¤šæ–°å•è¯å’Œæœ¯è¯­ã€‚ä½†æ˜¯æˆ‘ä¹Ÿè·³è¿‡äº†å‡ ä¸ªå‘é‡ä»£æ•°çš„æ·±å±‚æ¦‚å¿µã€‚è¿™å¯èƒ½æ˜¯å‹å€’æ€§çš„ï¼Œä½†æˆ‘ä»ç„¶ä½¿æ¦‚å¿µå°½å¯èƒ½å®ç”¨ï¼Œ(æ¬¢è¿åé¦ˆï¼).**

**ç”±äºæˆ‘åˆšåˆšå¼€å§‹æ·±åº¦å­¦ä¹ ï¼Œæˆ‘å†³å®šå¸®åŠ©å…¶ä»–å·²ç»å¼€å§‹çš„äººï¼Œä¸ºä»–ä»¬æä¾›å…³äºæ·±åº¦å­¦ä¹ æœ¯è¯­å’Œä¸œè¥¿çš„ç›´è§‚æ–‡ç« ã€‚æ‰€ä»¥å¦‚æœä½ è§‰å¾—è¿™äº›æ–‡ç« æœ‰ä»€ä¹ˆé”™è¯¯ï¼Œè¯·åœ¨è¯„è®ºä¸­å‘è¡¨ã€‚**

****ä»¥ä¸‹æ˜¯ä¸€äº›æœ‰ç”¨çš„èµ„æº:****

**æ·±å…¥ç›´è§‚çš„çº¿æ€§ä»£æ•°è§†é¢‘: [3blue1brown](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)**

**ç”µå­ä¹¦:[https://www.math.ucdavis.edu/~linear/linear-guest.pdf](https://www.math.ucdavis.edu/~linear/linear-guest.pdf)**

**å­¦ä¹ æ·±åº¦å­¦ä¹ çš„æœ€ä½³ç«™ç‚¹: [fast.ai](https://www.fast.ai/)**

**ä¸€æœ¬å®Œæ•´çš„å­¦ä¹ ä¹¦:[æ·±åº¦å­¦ä¹ ä¹¦ï¼Œä½œè€… Ian Goodfellowã€‚](https://www.deeplearningbook.org/)**

**![](img/6d60b235fcc46a4bd696b90e886419ee.png)**