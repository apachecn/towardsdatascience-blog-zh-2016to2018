<html>
<head>
<title>Artificial Intelligence meets Art: Neural Transfer Style</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">äººå·¥æ™ºèƒ½é‡è§è‰ºæœ¯:ç¥ç»ä¼ é€’é£æ ¼</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/artificial-intelligence-meets-art-neural-transfer-style-50e1c07aa7f7?source=collection_archive---------7-----------------------#2018-11-08">https://towardsdatascience.com/artificial-intelligence-meets-art-neural-transfer-style-50e1c07aa7f7?source=collection_archive---------7-----------------------#2018-11-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/0becfa773bde9af462af48fdbc03de3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p06Rgst1a_7mXl8-N_hXYQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Hokusai in Boston</figcaption></figure><h1 id="07dc" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">ä»‹ç»</h1><p id="4db6" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">ç¥ç»è½¬ç§»é£æ ¼æ˜¯äººå·¥æ™ºèƒ½åœ¨åˆ›é€ æ€§èƒŒæ™¯ä¸‹æœ€ä»¤äººæƒŠå¹çš„åº”ç”¨ä¹‹ä¸€ã€‚åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å°†è‰ºæœ¯ç»˜ç”»é£æ ¼è½¬ç§»åˆ°é€‰å®šçš„å›¾åƒä¸Šï¼Œåˆ›é€ å‡ºä»¤äººæƒŠå¹çš„æ•ˆæœã€‚Leon A. Gatys ç­‰äººåœ¨ 2015 å¹´çš„è®ºæ–‡<a class="ae ly" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank"> <em class="lz">ä¸­æ„æ€äº†<strong class="lc ir">ç¥ç»ä¼ é€’é£æ ¼</strong>çš„æ¦‚å¿µï¼Œä¸€ç§è‰ºæœ¯é£æ ¼</em> </a>çš„ç¥ç»ç®—æ³•ã€‚åœ¨é‚£ä¹‹åï¼Œè®¸å¤šç ”ç©¶äººå‘˜åº”ç”¨å¹¶æ”¹è¿›äº†è¿™ç§æ–¹æ³•ï¼Œå¢åŠ äº†æŸå¤±çš„å…ƒç´ ï¼Œå°è¯•äº†ä¸åŒçš„ä¼˜åŒ–å™¨ï¼Œå¹¶è¯•éªŒäº†ç”¨äºæ­¤ç›®çš„çš„ä¸åŒç¥ç»ç½‘ç»œã€‚<br/>å°½ç®¡å¦‚æ­¤ï¼ŒåŸå§‹è®ºæ–‡ä»ç„¶æ˜¯ç†è§£è¿™ä¸€æ¦‚å¿µçš„æœ€ä½³æ¥æºï¼ŒVGG16 å’Œ VGG19 ç½‘ç»œæ˜¯è¿™æ–¹é¢æœ€å¸¸ç”¨çš„æ¨¡å‹ã€‚è¿™ç§é€‰æ‹©æ˜¯ä¸å¯»å¸¸çš„ï¼Œè€ƒè™‘åˆ°ä¸¤è€…éƒ½è¢«æœ€è¿‘çš„ç½‘ç»œè¶…è¶Šï¼Œåœ¨é£æ ¼è½¬ç§»ä¸­å®ç°çš„æœ€é«˜æ€§èƒ½è¯æ˜äº†è¿™ä¸€ç‚¹ã€‚</p><p id="20dc" class="pw-post-body-paragraph la lb iq lc b ld ma lf lg lh mb lj lk ll mc ln lo lp md lr ls lt me lv lw lx ij bi translated">å®Œæ•´ä»£ç å¯ä»¥æŸ¥çœ‹è¿™ä¸ª<a class="ae ly" href="https://github.com/maurock/neural_transfer_style" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ir"> GitHub åº“</strong> </a> <strong class="lc ir"> </strong>ã€‚</p><h1 id="4685" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ</h1><p id="6600" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">è¿™ç§æŠ€æœ¯çš„ç›®æ ‡æ˜¯å°†å›¾åƒçš„æ ·å¼(æˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œæ ·å¼å›¾åƒâ€)åº”ç”¨åˆ°ç›®æ ‡å›¾åƒï¼Œä¿ç•™åè€…çš„å†…å®¹ã€‚è®©æˆ‘ä»¬å®šä¹‰è¿™ä¸¤ä¸ªæœ¯è¯­:</p><ul class=""><li id="d081" class="mf mg iq lc b ld ma lh mb ll mh lp mi lt mj lx mk ml mm mn bi translated"><strong class="lc ir">é£æ ¼</strong>æ˜¯å›¾åƒä¸­çš„çº¹ç†å’Œè§†è§‰æ¨¡å¼ã€‚ä¸€ä¸ªä¾‹å­æ˜¯è‰ºæœ¯å®¶çš„ç¬”è§¦ã€‚</li><li id="4a27" class="mf mg iq lc b ld mo lh mp ll mq lp mr lt ms lx mk ml mm mn bi translated"><strong class="lc ir">å†…å®¹</strong>æ˜¯ä¸€å¹…å›¾åƒçš„å®è§‚ç»“æ„ã€‚äººã€å»ºç­‘ç‰©ã€ç‰©ä½“éƒ½æ˜¯å›¾åƒå†…å®¹çš„ä¾‹å­ã€‚</li></ul><p id="55c0" class="pw-post-body-paragraph la lb iq lc b ld ma lf lg lh mb lj lk ll mc ln lo lp md lr ls lt me lv lw lx ij bi translated">ä»¤äººæƒŠå¹çš„æ•ˆæœå¦‚ä¸‹æ‰€ç¤º:</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mt"><img src="../Images/4da9bac3d1d2ce1f495d9d539a411e9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*tBCPZpaGYX7gTobCMpAp_Q.gif"/></div></div></figure><blockquote class="my"><p id="7fef" class="mz na iq bd nb nc nd ne nf ng nh lx dk translated">ä½ æƒ³çœ‹åˆ°æ›´å¤šçš„æ•ˆæœå—ï¼Ÿåœ¨æ–‡ç« çš„æœ€åæ£€æŸ¥ä»–ä»¬ï¼</p></blockquote><p id="3f91" class="pw-post-body-paragraph la lb iq lc b ld ni lf lg lh nj lj lk ll nk ln lo lp nl lr ls lt nm lv lw lx ij bi translated">è®©æˆ‘ä»¬çœ‹çœ‹é«˜çº§æ­¥éª¤:</p><ul class=""><li id="b00b" class="mf mg iq lc b ld ma lh mb ll mh lp mi lt mj lx mk ml mm mn bi translated">é€‰æ‹©è¦æ ·å¼åŒ–çš„å›¾åƒ</li><li id="9219" class="mf mg iq lc b ld mo lh mp ll mq lp mr lt ms lx mk ml mm mn bi translated">é€‰æ‹©æ ·å¼å‚è€ƒå›¾åƒã€‚é€šå¸¸ï¼Œè¿™æ˜¯ä¸€å¹…é£æ ¼å¥‡ç‰¹ä¸”æ˜“äºè¾¨è®¤çš„ç”»ã€‚</li><li id="e039" class="mf mg iq lc b ld mo lh mp ll mq lp mr lt ms lx mk ml mm mn bi translated">åˆå§‹åŒ–é¢„è®­ç»ƒçš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå¹¶è·å¾—ä¸­é—´å±‚çš„ç‰¹å¾è¡¨ç¤ºã€‚å®Œæˆè¯¥æ­¥éª¤æ˜¯ä¸ºäº†å®ç°å†…å®¹å›¾åƒå’Œæ ·å¼å›¾åƒçš„è¡¨ç¤ºã€‚åœ¨å†…å®¹å›¾åƒä¸­ï¼Œæœ€å¥½çš„é€‰æ‹©æ˜¯è·å¾—æœ€é«˜å±‚çš„ç‰¹å¾è¡¨ç¤ºï¼Œå› ä¸ºå®ƒä»¬åŒ…å«å…³äºå›¾åƒå®è§‚ç»“æ„çš„ä¿¡æ¯ã€‚å¯¹äºæ ·å¼å‚è€ƒå½±åƒï¼Œä»ä¸åŒæ¯”ä¾‹çš„å¤šä¸ªå›¾å±‚ä¸­è·å–è¦ç´ åˆ¶å›¾è¡¨è¾¾ã€‚</li><li id="fe03" class="mf mg iq lc b ld mo lh mp ll mq lp mr lt ms lx mk ml mm mn bi translated">å°†æœ€å°åŒ–çš„æŸå¤±å‡½æ•°å®šä¹‰ä¸º<em class="lz">å†…å®¹æŸå¤±</em>ã€<em class="lz">é£æ ¼æŸå¤±</em>å’Œ<em class="lz">å˜åŒ–æŸå¤±</em>ä¹‹å’Œã€‚æ¯æ¬¡è¿­ä»£ï¼Œä¼˜åŒ–å™¨éƒ½ä¼šç”Ÿæˆä¸€å¹…å›¾åƒã€‚å†…å®¹æŸå¤±æ˜¯ç”Ÿæˆå›¾åƒå’Œå†…å®¹å›¾åƒä¹‹é—´çš„å·®å¼‚(l2 å½’ä¸€åŒ–)ï¼Œè€Œæ ·å¼æŸå¤±æ˜¯ç”Ÿæˆå›¾åƒå’Œæ ·å¼ä¹‹é—´çš„å·®å¼‚ã€‚æˆ‘ä»¬ç¨åä¼šçœ‹åˆ°è¿™äº›å˜é‡æ˜¯å¦‚ä½•è¢«æ•°å­¦å®šä¹‰çš„ã€‚</li><li id="b10b" class="mf mg iq lc b ld mo lh mp ll mq lp mr lt ms lx mk ml mm mn bi translated">é‡å¤æœ€å°åŒ–æŸå¤±</li></ul><h1 id="b797" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">å¤„ç†å’Œå–æ¶ˆå¤„ç†å›¾åƒ</h1><p id="d0a8" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æ ¼å¼åŒ–æˆ‘ä»¬çš„å›¾åƒä»¥ä¾›æˆ‘ä»¬çš„ç½‘ç»œä½¿ç”¨ã€‚æˆ‘ä»¬è¦ç”¨çš„ CNN æ˜¯é¢„å…ˆè®­ç»ƒå¥½çš„ VGG19 convnetã€‚å½“æˆ‘ä»¬å°†å›¾åƒå¤„ç†æˆå…¼å®¹çš„æ•°ç»„æ—¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦å¯¹ç”Ÿæˆçš„å›¾åƒè¿›è¡Œè§£å¤„ç†ï¼Œä» BGR æ ¼å¼åˆ‡æ¢åˆ° RGB æ ¼å¼ã€‚è®©æˆ‘ä»¬æ„å»ºä¸¤ä¸ªè¾…åŠ©å‡½æ•°æ¥å®ç°è¿™ä¸€ç‚¹:</p><pre class="mu mv mw mx gt nn no np nq aw nr bi"><span id="b248" class="ns kd iq no b gy nt nu l nv nw"># Preprocessing image to make it compatible with the VGG19 model<br/><strong class="no ir">def</strong> <strong class="no ir">preprocess_image</strong>(image_path):<br/>    img = load_img(image_path, target_size=(resized_width, resized_height))<br/>    img = img_to_array(img)<br/>    img = np.expand_dims(img, axis=<strong class="no ir">0</strong>)<br/>    img = vgg19.preprocess_input(img)<br/>    <strong class="no ir">return</strong> img<br/><br/># Function to convert a tensor into an image<br/><strong class="no ir">def</strong> <strong class="no ir">deprocess_image</strong>(x):<br/>    x = x.reshape((resized_width, resized_height, <strong class="no ir">3</strong>))<br/><br/>    # Remove zero-center by mean pixel. Necessary when working with VGG model<br/>    x[:, :, <strong class="no ir">0</strong>] += <strong class="no ir">103.939</strong><br/>    x[:, :, <strong class="no ir">1</strong>] += <strong class="no ir">116.779</strong><br/>    x[:, :, <strong class="no ir">2</strong>] += <strong class="no ir">123.68</strong><br/><br/>    # Format BGR-&gt;RGB<br/>    x = x[:, :, ::-<strong class="no ir">1</strong>]<br/>    x = np.clip(x, <strong class="no ir">0</strong>, <strong class="no ir">255</strong>).astype('uint8')<br/>    <strong class="no ir">return</strong> x</span></pre><h1 id="f776" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">å†…å®¹æŸå¤±</h1><p id="db6d" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">å†…å®¹æŸå¤±å°†ä¸»è¾“å…¥å›¾åƒçš„å†…å®¹ä¿ç•™åˆ°æ ·å¼ä¸­ã€‚ç”±äºå·ç§¯ç¥ç»ç½‘ç»œçš„è¾ƒé«˜å±‚åŒ…å«å›¾åƒå®è§‚ç»“æ„çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å°†å†…å®¹æŸå¤±è®¡ç®—ä¸ºè¾“å…¥å›¾åƒçš„æœ€é«˜å±‚çš„è¾“å‡ºå’Œç”Ÿæˆå›¾åƒçš„ç›¸åŒå±‚ä¹‹é—´çš„å·®å¼‚(l2 å½’ä¸€åŒ–)ã€‚<br/>å†…å®¹æŸå¤±å®šä¹‰ä¸º:</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/9417fb28773fcddc8dcebca4721a8a25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*mx_6OSVh6QGnWhJuRJjZYw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Content loss</figcaption></figure><p id="67c6" class="pw-post-body-paragraph la lb iq lc b ld ma lf lg lh mb lj lk ll mc ln lo lp md lr ls lt me lv lw lx ij bi translated">åœ¨ç­‰å¼ä¸­ï¼Œ<em class="lz"> F </em>æ˜¯å†…å®¹å›¾åƒçš„ç‰¹å¾è¡¨ç¤º(å½“æˆ‘ä»¬è¿è¡Œæˆ‘ä»¬çš„è¾“å…¥å›¾åƒæ—¶ï¼Œç½‘ç»œè¾“å‡ºçš„å†…å®¹)ï¼Œè€Œ<em class="lz"> P </em>æ˜¯åœ¨ç‰¹å®šéšè—å±‚<em class="lz"> l </em>ç”Ÿæˆçš„å›¾åƒçš„ç‰¹å¾è¡¨ç¤ºã€‚<br/>å®ç°å¦‚ä¸‹:</p><pre class="mu mv mw mx gt nn no np nq aw nr bi"><span id="70c1" class="ns kd iq no b gy nt nu l nv nw"># The content loss maintains the features of the content image in the generated image.<br/><strong class="no ir">def</strong> <strong class="no ir">content_loss</strong>(layer_features):<br/>    base_image_features = layer_features[<strong class="no ir">0</strong>, :, :, :]<br/>    combination_features = layer_features[<strong class="no ir">2</strong>, :, :, :]<br/>    <strong class="no ir">return</strong> K.sum(K.square(combination_features - base_image_features))</span></pre><h1 id="e78c" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">é£æ ¼ä¸§å¤±</h1><p id="fb9b" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">ç†è§£é£æ ¼æŸå¤±ä¸åƒç†è§£å†…å®¹æŸå¤±é‚£ä¹ˆç®€å•ã€‚ç›®æ ‡æ˜¯åœ¨æ–°ç”Ÿæˆçš„å›¾åƒä¸­ä¿ç•™å›¾åƒçš„æ ·å¼(å³ï¼Œä½œä¸ºç¬”è§¦çš„è§†è§‰å›¾æ¡ˆ)ã€‚åœ¨å‰ä¸€ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†ä¸­é—´å±‚çš„åŸå§‹è¾“å‡ºã€‚è¿™é‡Œï¼Œæˆ‘ä»¬æ¯”è¾ƒæ ·å¼å‚è€ƒå›¾åƒå’Œç”Ÿæˆå›¾åƒçš„ç‰¹å®šå±‚çš„ Gram çŸ©é˜µä¹‹é—´çš„å·®å¼‚ã€‚<strong class="lc ir"> Gram çŸ©é˜µ</strong>è¢«å®šä¹‰ä¸ºç»™å®šå±‚çš„çŸ¢é‡åŒ–ç‰¹å¾å›¾ä¹‹é—´çš„å†…ç§¯ã€‚çŸ©é˜µçš„æ„ä¹‰åœ¨äºæ•æ‰å±‚ç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§ã€‚è®¡ç®—å¤šä¸ªå±‚çš„æŸå¤±å…è®¸åœ¨æ ·å¼å›¾åƒå’Œç”Ÿæˆçš„å›¾åƒä¹‹é—´ä¿ç•™ä¸åŒå±‚ä¸­å†…éƒ¨ç›¸å…³çš„ç›¸ä¼¼ç‰¹å¾ã€‚<br/>å•å±‚çš„é£æ ¼æŸå¤±è®¡ç®—å¦‚ä¸‹:</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ny"><img src="../Images/b2ba623ff3bbdded849f686be4634cf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Shg5dNFvlt7M8xH3AKyIpg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Style loss per layer</figcaption></figure><p id="9048" class="pw-post-body-paragraph la lb iq lc b ld ma lf lg lh mb lj lk ll mc ln lo lp md lr ls lt me lv lw lx ij bi translated">åœ¨ç­‰å¼ä¸­ï¼Œ<em class="lz"> A </em>æ˜¯æ ·å¼å›¾åƒçš„ Gram çŸ©é˜µï¼Œ<em class="lz"> G </em>æ˜¯ç”Ÿæˆçš„å›¾åƒçš„ Gram çŸ©é˜µï¼Œä¸¤è€…éƒ½ä¸ç»™å®šçš„å±‚æœ‰å…³ã€‚<em class="lz"> N </em>å’Œ<em class="lz"> M </em>ä¸ºæ ·å¼å›¾åƒçš„å®½åº¦å’Œé«˜åº¦ã€‚<br/>åœ¨ç­‰å¼ä¸­ï¼Œ<em class="lz"> A </em>æ˜¯é£æ ¼å›¾åƒçš„å…‹çŸ©é˜µï¼Œ<em class="lz"> G </em>æ˜¯ç”Ÿæˆçš„å›¾åƒçš„å…‹çŸ©é˜µï¼Œä¸¤è€…éƒ½ä¸ç»™å®šçš„å±‚æœ‰å…³ã€‚<em class="lz"> N </em>å’Œ<em class="lz"> M </em>ä¸ºæ ·å¼å›¾åƒçš„å®½åº¦å’Œé«˜åº¦ã€‚<br/>é¦–å…ˆä¸ºæ¯ä¸ªå•ç‹¬çš„å±‚è®¡ç®—æ ·å¼æŸå¤±ï¼Œç„¶åå°†å…¶åº”ç”¨äºè¢«è®¤ä¸ºæ˜¯å¯¹æ ·å¼å»ºæ¨¡çš„æ¯ä¸ªå±‚ã€‚è®©æˆ‘ä»¬æ¥å®ç°å®ƒ:</p><pre class="mu mv mw mx gt nn no np nq aw nr bi"><span id="8bd4" class="ns kd iq no b gy nt nu l nv nw"># The gram matrix of an image tensor is the inner product between the vectorized feature map in a layer.<br/># It is used to compute the style loss, minimizing the mean squared distance between the feature correlation map of the style image<br/># and the input image<br/><strong class="no ir">def</strong> <strong class="no ir">gram_matrix</strong>(x):<br/>    features = K.batch_flatten(K.permute_dimensions(x, (<strong class="no ir">2</strong>, <strong class="no ir">0</strong>, <strong class="no ir">1</strong>)))<br/>    gram = K.dot(features, K.transpose(features))<br/>    <strong class="no ir">return</strong> gram<br/><br/><br/># The style_loss_per_layer represents the loss between the style of the style reference image and the generated image.<br/># It depends on the gram matrices of feature maps from the style reference image and from the generated image.<br/><strong class="no ir">def</strong> <strong class="no ir">style_loss_per_layer</strong>(style, combination):<br/>    S = gram_matrix(style)<br/>    C = gram_matrix(combination)<br/>    channels = <strong class="no ir">3</strong><br/>    size = resized_width * resized_height<br/>    <strong class="no ir">return</strong> K.sum(K.square(S - C)) / (<strong class="no ir">4.</strong> * (channels ** <strong class="no ir">2</strong>) * (size ** <strong class="no ir">2</strong>))<br/><br/># The total_style_loss represents the total loss between the style of the style reference image and the generated image,<br/># taking into account all the layers considered for the style transfer, related to the style reference image.<br/><strong class="no ir">def</strong> <strong class="no ir">total_style_loss</strong>(feature_layers):<br/>    loss = K.variable(<strong class="no ir">0.</strong>)<br/>    <strong class="no ir">for</strong> layer_name <strong class="no ir">in</strong> feature_layers:<br/>        layer_features = outputs_dict[layer_name]<br/>        style_reference_features = layer_features[<strong class="no ir">1</strong>, :, :, :]<br/>        combination_features = layer_features[<strong class="no ir">2</strong>, :, :, :]<br/>        sl = style_loss_per_layer(style_reference_features, combination_features)<br/>        loss += (style_weight / len(feature_layers)) * sl<br/>    <strong class="no ir">return</strong> loss</span></pre><h1 id="6552" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">å˜å¼‚æŸå¤±</h1><p id="3da7" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">æœ€åï¼ŒæŸå¤±çš„æœ€åä¸€éƒ¨åˆ†æ˜¯å˜å¼‚æŸå¤±ã€‚åŸå§‹è®ºæ–‡ä¸­æ²¡æœ‰åŒ…æ‹¬è¿™ä¸€è¦ç´ ï¼Œä¸¥æ ¼æ¥è¯´ï¼Œå®ƒå¯¹äºé¡¹ç›®çš„æˆåŠŸå¹¶ä¸æ˜¯å¿…è¦çš„ã€‚å°½ç®¡å¦‚æ­¤ï¼Œç»éªŒè¯æ˜ï¼Œæ·»åŠ è¯¥å…ƒç´ ä¼šäº§ç”Ÿæ›´å¥½çš„ç»“æœï¼Œå› ä¸ºå®ƒå¹³æ»‘äº†ç›¸é‚»åƒç´ ä¹‹é—´çš„é¢œè‰²å˜åŒ–ã€‚è®©æˆ‘ä»¬æŠŠè¿™ä¸ªåŒ…æ‹¬è¿›å»:</p><pre class="mu mv mw mx gt nn no np nq aw nr bi"><span id="b52d" class="ns kd iq no b gy nt nu l nv nw"># The total variation loss mantains the generated image loclaly coherent,<br/># smoothing the pixel variations among neighbour pixels.<br/><strong class="no ir">def</strong> <strong class="no ir">total_variation_loss</strong>(x):<br/>    a = K.square(x[:, :resized_width - <strong class="no ir">1</strong>, :resized_height - <strong class="no ir">1</strong>, :] - x[:, <strong class="no ir">1</strong>:, :resized_height - <strong class="no ir">1</strong>, :])<br/>    b = K.square(x[:, :resized_width - <strong class="no ir">1</strong>, :resized_height - <strong class="no ir">1</strong>, :] - x[:, :resized_width - <strong class="no ir">1</strong>, <strong class="no ir">1</strong>:, :])<br/>    <strong class="no ir">return</strong> K.sum(K.pow(a + b, <strong class="no ir">1.25</strong>))</span></pre><h1 id="1503" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">å…¨æŸ</h1><p id="8187" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">æœ€åï¼Œå°†æ‰€æœ‰è¿™äº›å› ç´ è€ƒè™‘åœ¨å†…ï¼Œè®¡ç®—æ€»æŸå¤±ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æå–æˆ‘ä»¬é€‰æ‹©çš„ç‰¹å®šå±‚çš„è¾“å‡ºã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå­—å…¸ä¸º&lt;<em class="lz">å±‚åï¼Œå±‚è¾“å‡º</em> &gt;:</p><pre class="mu mv mw mx gt nn no np nq aw nr bi"><span id="1ff7" class="ns kd iq no b gy nt nu l nv nw"># Get the outputs of each key layer, through unique names.<br/>outputs_dict = dict([(layer.name, layer.output) <strong class="no ir">for</strong> layer <strong class="no ir">in</strong> model.layers])</span></pre><p id="b831" class="pw-post-body-paragraph la lb iq lc b ld ma lf lg lh mb lj lk ll mc ln lo lp md lr ls lt me lv lw lx ij bi translated">ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡è°ƒç”¨å…ˆå‰ç¼–ç çš„å‡½æ•°æ¥è®¡ç®—æŸå¤±ã€‚æ¯ä¸ªåˆ†é‡éƒ½ä¹˜ä»¥ç‰¹å®šçš„æƒé‡ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒæ•´æƒé‡ä»¥äº§ç”Ÿå¼ºçƒˆæˆ–è¾ƒè½»çš„æ•ˆæœ:</p><pre class="mu mv mw mx gt nn no np nq aw nr bi"><span id="ea70" class="ns kd iq no b gy nt nu l nv nw"><strong class="no ir">def</strong> <strong class="no ir">total_loss</strong>():<br/>    loss = K.variable(<strong class="no ir">0.</strong>)<br/><br/>    # contribution of content_loss<br/>    feature_layers_content = outputs_dict['block5_conv2']<br/>    loss += content_weight * content_loss(feature_layers_content)<br/><br/>    # contribution of style_loss<br/>    feature_layers_style = ['block1_conv1', 'block2_conv1',<br/>                            'block3_conv1', 'block4_conv1',<br/>                            'block5_conv1']<br/>    loss += total_style_loss(feature_layers_style) * style_weight<br/><br/>    # contribution of variation_loss<br/>    loss += total_variation_weight * total_variation_loss(combination_image)<br/>    <strong class="no ir">return</strong> loss</span></pre><h1 id="c907" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">è®¾ç½®ç¥ç»ç½‘ç»œ</h1><p id="ff3f" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">VGG19 ç½‘ç»œå°†ä¸€æ‰¹ä¸‰ä¸ªå›¾åƒä½œä¸ºè¾“å…¥:è¾“å…¥å†…å®¹å›¾åƒã€æ ·å¼å‚è€ƒå›¾åƒå’ŒåŒ…å«ç”Ÿæˆå›¾åƒçš„ç¬¦å·å¼ é‡ã€‚å‰ä¸¤ä¸ªæ˜¯å¸¸é‡å˜é‡ï¼Œä½¿ç”¨ keras.backend åŒ…å®šä¹‰ä¸º<em class="lz">å˜é‡</em>ã€‚ç¬¬ä¸‰ä¸ªå˜é‡å®šä¹‰ä¸º<em class="lz">å ä½ç¬¦</em>ï¼Œå› ä¸ºå®ƒä¼šéšç€ä¼˜åŒ–å™¨æ›´æ–°ç»“æœçš„æ—¶é—´è€Œå˜åŒ–ã€‚</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/a73d5c3461c5f304037056115aaa683e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*gASPVOwJJq-EoviO02Iw0w.jpeg"/></div></figure><p id="3ab7" class="pw-post-body-paragraph la lb iq lc b ld ma lf lg lh mb lj lk ll mc ln lo lp md lr ls lt me lv lw lx ij bi translated">ä¸€æ—¦å˜é‡è¢«åˆå§‹åŒ–ï¼Œæˆ‘ä»¬å°±æŠŠå®ƒä»¬åŠ å…¥ä¸€ä¸ªå¼ é‡ï¼Œè¿™ä¸ªå¼ é‡å°†åœ¨ä»¥åæä¾›ç»™ç½‘ç»œã€‚</p><pre class="mu mv mw mx gt nn no np nq aw nr bi"><span id="9c6c" class="ns kd iq no b gy nt nu l nv nw"># Get tensor representations of our images<br/>base_image = K.variable(preprocess_image(base_image_path))<br/>style_reference_image = K.variable(preprocess_image(style_reference_image_path))<br/><br/># Placeholder for generated image<br/>combination_image = K.placeholder((<strong class="no ir">1</strong>, resized_width, resized_height, <strong class="no ir">3</strong>))<br/><br/># Combine the 3 images into a single Keras tensor<br/>input_tensor = K.concatenate([base_image,<br/>                              style_reference_image,<br/>                              combination_image], axis=<strong class="no ir">0</strong>)</span></pre><p id="4f3b" class="pw-post-body-paragraph la lb iq lc b ld ma lf lg lh mb lj lk ll mc ln lo lp md lr ls lt me lv lw lx ij bi translated">å®Œæˆåï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰æŸè€—ã€æ¢¯åº¦å’Œè¾“å‡ºã€‚åŸå§‹è®ºæ–‡ä½¿ç”¨ç®—æ³• L-BFGS ä½œä¸ºä¼˜åŒ–å™¨ã€‚è¿™ç§ç®—æ³•çš„ä¸€ä¸ªé™åˆ¶æ˜¯å®ƒè¦æ±‚æŸå¤±å’Œæ¢¯åº¦åˆ†åˆ«é€šè¿‡ã€‚å› ä¸ºå•ç‹¬è®¡ç®—å®ƒä»¬æ•ˆç‡æä½ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†å®ç°ä¸€ä¸ªèµ‹å€¼å™¨ç±»ï¼Œå®ƒå¯ä»¥åŒæ—¶è®¡ç®—æŸå¤±å’Œæ¢¯åº¦å€¼ï¼Œä½†åˆ†åˆ«è¿”å›å®ƒä»¬ã€‚è®©æˆ‘ä»¬è¿™æ ·åš:</p><pre class="mu mv mw mx gt nn no np nq aw nr bi"><span id="b96b" class="ns kd iq no b gy nt nu l nv nw">loss = total_loss()<br/><br/># Get the gradients of the generated image<br/>grads = K.gradients(loss, combination_image)<br/>outputs = [loss]<br/>outputs += grads<br/><br/>f_outputs = K.function([combination_image], outputs)<br/><br/># Evaluate the loss and the gradients respect to the generated image. It is called in the Evaluator, necessary to<br/># compute the gradients and the loss as two different functions (limitation of the L-BFGS algorithm) without<br/># excessive losses in performance<br/><strong class="no ir">def</strong> <strong class="no ir">eval_loss_and_grads</strong>(x):<br/>    x = x.reshape((<strong class="no ir">1</strong>, resized_width, resized_height, <strong class="no ir">3</strong>))<br/>    outs = f_outputs([x])<br/>    loss_value = outs[<strong class="no ir">0</strong>]<br/>    <strong class="no ir">if</strong> len(outs[<strong class="no ir">1</strong>:]) == <strong class="no ir">1</strong>:<br/>        grad_values = outs[<strong class="no ir">1</strong>].flatten().astype('float64')<br/>    <strong class="no ir">else</strong>:<br/>        grad_values = np.array(outs[<strong class="no ir">1</strong>:]).flatten().astype('float64')<br/>    <strong class="no ir">return</strong> loss_value, grad_values<br/><br/># Evaluator returns the loss and the gradient in two separate functions, but the calculation of the two variables<br/># are dependent. This reduces the computation time, since otherwise it would be calculated separately.<br/><strong class="no ir">class</strong> <strong class="no ir">Evaluator</strong>(object):<br/><br/>    <strong class="no ir">def</strong> <strong class="no ir">__init__</strong>(self):<br/>        self.loss_value = <strong class="no ir">None</strong><br/>        self.grads_values = <strong class="no ir">None</strong><br/><br/>    <strong class="no ir">def</strong> <strong class="no ir">loss</strong>(self, x):<br/>        <strong class="no ir">assert</strong> self.loss_value <strong class="no ir">is</strong> <strong class="no ir">None</strong><br/>        loss_value, grad_values = eval_loss_and_grads(x)<br/>        self.loss_value = loss_value<br/>        self.grad_values = grad_values<br/>        <strong class="no ir">return</strong> self.loss_value<br/><br/>    <strong class="no ir">def</strong> <strong class="no ir">grads</strong>(self, x):<br/>        <strong class="no ir">assert</strong> self.loss_value <strong class="no ir">is</strong> <strong class="no ir">not</strong> <strong class="no ir">None</strong><br/>        grad_values = np.copy(self.grad_values)<br/>        self.loss_value = <strong class="no ir">None</strong><br/>        self.grad_values = <strong class="no ir">None</strong><br/>        <strong class="no ir">return</strong> grad_values<br/><br/>evaluator = Evaluator()</span></pre><h1 id="b728" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">æœ€åä¸€æ¡£</h1><p id="3f2e" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">ç»ˆäºä¸‡äº‹ä¿±å¤‡äº†ï¼æœ€åä¸€æ­¥æ˜¯å¤šæ¬¡è¿­ä»£ä¼˜åŒ–å™¨ï¼Œç›´åˆ°æˆ‘ä»¬è¾¾åˆ°æœŸæœ›çš„æŸå¤±æˆ–æœŸæœ›çš„ç»“æœã€‚æˆ‘ä»¬å°†ä¿å­˜è¿­ä»£çš„ç»“æœï¼Œä»¥æ£€æŸ¥ç®—æ³•æ˜¯å¦æŒ‰é¢„æœŸå·¥ä½œã€‚å¦‚æœç»“æœä¸ä»¤äººæ»¡æ„ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒæ•´æƒé‡ä»¥æ”¹å–„ç”Ÿæˆçš„å›¾åƒã€‚</p><pre class="mu mv mw mx gt nn no np nq aw nr bi"><span id="bd81" class="ns kd iq no b gy nt nu l nv nw"># The oprimizer is fmin_l_bfgs<br/><strong class="no ir">for</strong> i <strong class="no ir">in</strong> range(iterations):<br/>    print('Iteration: ', i)<br/>    x, min_val, info = fmin_l_bfgs_b(evaluator.loss,<br/>                                     x.flatten(),<br/>                                     fprime=evaluator.grads,<br/>                                     maxfun=<strong class="no ir">15</strong>)<br/><br/>    print('Current loss value:', min_val)<br/><br/>    # Save current generated image<br/>    img = deprocess_image(x.copy())<br/>    fname = 'img/new' + np.str(i) + '.png'<br/>    save(fname, img)</span></pre><p id="2a2a" class="pw-post-body-paragraph la lb iq lc b ld ma lf lg lh mb lj lk ll mc ln lo lp md lr ls lt me lv lw lx ij bi translated">è¦æŸ¥çœ‹å®Œæ•´ä»£ç ï¼Œè¯·å‚è€ƒé¡µé¢å¼€å¤´æä¾›çš„ GitHub é“¾æ¥ã€‚</p><h1 id="3e1f" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">æƒŠäººçš„ç»“æœ</h1><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oa"><img src="../Images/543654a95d45d3361475770f5d3714a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*kdUTCYnmfliMngQ_Y9g6og.gif"/></div></div></figure><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ob"><img src="../Images/2610bc33e817664db42274ae74b32dbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EInbyrqdhszURjRCYVeMIA.png"/></div></div></figure><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/6a3bee3e5029daa618938b248828166d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BgS6uhsspFM-lq8E5okOtg.png"/></div></div></figure><blockquote class="od oe of"><p id="2b61" class="la lb lz lc b ld ma lf lg lh mb lj lk og mc ln lo oh md lr ls oi me lv lw lx ij bi translated">å¦‚æœä½ æƒ³å°è¯•ç‰¹å®šçš„æ•ˆæœï¼Œç»˜ç”»ï¼Œæˆ–è€…ä½ æœ‰ä»»ä½•å»ºè®®ï¼Œè¯·ç•™ä¸‹è¯„è®ºï¼</p></blockquote><p id="a4c4" class="pw-post-body-paragraph la lb iq lc b ld ma lf lg lh mb lj lk ll mc ln lo lp md lr ls lt me lv lw lx ij bi translated"><em class="lz">å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œæˆ‘å¸Œæœ›ä½ èƒ½ç‚¹å‡»é¼“æŒæŒ‰é’®</em>ğŸ‘å› æ­¤å…¶ä»–äººå¯èƒ½ä¼šå¶ç„¶å‘ç°å®ƒã€‚å¯¹äºä»»ä½•æ„è§æˆ–å»ºè®®ï¼Œä¸è¦çŠ¹è±«ç•™ä¸‹è¯„è®ºï¼</p></div><div class="ab cl oj ok hu ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="ij ik il im in"><h2 id="f93c" class="ns kd iq bd ke oq or dn ki os ot dp km ll ou ov kq lp ow ox ku lt oy oz ky pa bi translated">æˆ‘æ˜¯ä¸€åæ•°æ®ç§‘å­¦ä¸“ä¸šçš„å­¦ç”Ÿï¼Œçƒ­çˆ±æœºå™¨å­¦ä¹ åŠå…¶æ— å°½çš„åº”ç”¨ã€‚ä½ å¯ä»¥åœ¨ maurocomi.com<a class="ae ly" href="http://www.maurocomi.com" rel="noopener ugc nofollow" target="_blank">æ‰¾åˆ°æ›´å¤šå…³äºæˆ‘å’Œæˆ‘çš„é¡¹ç›®çš„ä¿¡æ¯ã€‚ä½ ä¹Ÿå¯ä»¥åœ¨</a><a class="ae ly" href="https://www.linkedin.com/in/mauro-comi/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>ä¸Šæ‰¾åˆ°æˆ‘ï¼Œæˆ–è€…ç›´æ¥ç»™æˆ‘å‘é‚®ä»¶ã€‚æˆ‘æ€»æ˜¯ä¹äºèŠå¤©ï¼Œæˆ–è€…åˆä½œæ–°çš„ä»¤äººæƒŠå¥‡çš„é¡¹ç›®ã€‚</h2></div></div>    
</body>
</html>