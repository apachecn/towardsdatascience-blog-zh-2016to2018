# ä½¿ç”¨ NumPy å’Œ Google Sheets çš„ Word2Vec å®ç°æŒ‡å—

> åŸæ–‡ï¼š<https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281?source=collection_archive---------1----------------------->

## äº†è§£ Word2Vec çš„å†…éƒ¨å·¥ä½œåŸç†

æœ¬æ–‡æ˜¯ä½¿ç”¨ NumPy å’Œ Google Sheets å®ç° Word2Vec çš„æŒ‡å—ã€‚å¦‚æœä½ è¯»è¿™ç¯‡æ–‡ç« æœ‰å›°éš¾ï¼Œå¯ä»¥è€ƒè™‘åœ¨è¿™é‡Œè®¢é˜…ä¸­çº§ä¼šå‘˜ï¼

Word2Vec è¢«èª‰ä¸ºè‡ªç„¶è¯­è¨€å¤„ç†(NLP)é¢†åŸŸæœ€å¤§ã€æœ€æ–°çš„çªç ´ä¹‹ä¸€ã€‚è¿™ä¸ªæ¦‚å¿µç®€å•ã€ä¼˜é›…ä¸”(ç›¸å¯¹)å®¹æ˜“æŒæ¡ã€‚å¿«é€Ÿçš„è°·æ­Œæœç´¢ä¼šè¿”å›å¤šä¸ªå…³äºå¦‚ä½•ä½¿ç”¨æ ‡å‡†åº“çš„ç»“æœï¼Œæ¯”å¦‚ [Gensim](https://radimrehurek.com/gensim/models/word2vec.html) å’Œ [TensorFlow](https://www.tensorflow.org/tutorials/representation/word2vec) ã€‚æ­¤å¤–ï¼Œå‡ºäºå¥½å¥‡ï¼Œè¯·æŸ¥çœ‹ Tomas Mikolov ä½¿ç”¨ C çš„åŸå§‹å®ç°ã€‚åŸæ–‡å¯ä»¥åœ¨[è¿™é‡Œ](https://arxiv.org/pdf/1301.3781.pdf)æ‰¾åˆ°ã€‚

æœ¬æ–‡çš„é‡ç‚¹æ˜¯è¯¦ç»†ä»‹ç» Word2Vecã€‚ä¸ºæ­¤ï¼Œæˆ‘ä½¿ç”¨ NumPy åœ¨ Python ä¸Šå®ç°äº† Word2Vec(åœ¨å…¶ä»–æ•™ç¨‹çš„å¸®åŠ©ä¸‹),è¿˜å‡†å¤‡äº†ä¸€ä¸ª Google å·¥ä½œè¡¨æ¥å±•ç¤ºè®¡ç®—ã€‚ä»¥ä¸‹æ˜¯[ä»£ç ](https://github.com/DerekChia/word2vec_numpy)å’Œ[è°·æ­Œè¡¨å•](https://docs.google.com/spreadsheets/u/3/d/1mgf82Ue7MmQixMm2ZqnT1oWUucj6pEcd2wDs_JgHmco/edit?usp=sharing)çš„é“¾æ¥ã€‚

![](img/d04b4e72229e7b9ff28d739353eb7c2b.png)

Fig. 1 â€” Step-by-step introduction to Word2Vec. Presented in code and Google Sheets

# ç›´è§‰

Word2Vec çš„ç›®æ ‡æ˜¯ä¸ºè¿›ä¸€æ­¥çš„ NLP ä»»åŠ¡ç”Ÿæˆå¸¦æœ‰è¯­ä¹‰çš„å•è¯çš„å‘é‡è¡¨ç¤ºã€‚æ¯ä¸ªå•è¯å‘é‡é€šå¸¸æœ‰å‡ ç™¾ä¸ªç»´åº¦ï¼Œå¹¶ä¸”è¯­æ–™åº“ä¸­çš„æ¯ä¸ªå”¯ä¸€å•è¯è¢«åˆ†é…ä¸€ä¸ªç©ºé—´å‘é‡ã€‚ä¾‹å¦‚ï¼Œå•è¯â€œhappyâ€å¯ä»¥è¡¨ç¤ºä¸º 4 ç»´å‘é‡[0.24ï¼Œ0.45ï¼Œ0.11ï¼Œ0.49],â€œsadâ€å…·æœ‰å‘é‡[0.88ï¼Œ0.78ï¼Œ0.45ï¼Œ0.91]ã€‚

å•è¯åˆ°å‘é‡çš„è½¬æ¢ä¹Ÿç§°ä¸º [*å•è¯åµŒå…¥*](https://en.wikipedia.org/wiki/Word_embedding) *ã€‚*ä¹‹æ‰€ä»¥è¦è¿›è¡Œè¿™æ ·çš„è½¬æ¢ï¼Œæ˜¯ä¸ºäº†è®©æœºå™¨å­¦ä¹ ç®—æ³•å¯ä»¥å¯¹æ•°å­—(åœ¨å‘é‡ä¸­)è€Œä¸æ˜¯å•è¯è¿›è¡Œçº¿æ€§ä»£æ•°è¿ç®—ã€‚

è¦å®ç° Word2Vecï¼Œæœ‰ä¸¤ç§é£æ ¼å¯ä¾›é€‰æ‹©â€” **è¿ç»­è¯åŒ…(CBOW)** æˆ–**è¿ç»­è·³æ ¼(SG)** ã€‚ç®€è€Œè¨€ä¹‹ï¼ŒCBOW è¯•å›¾ä»å…¶ç›¸é‚»å•è¯(ä¸Šä¸‹æ–‡å•è¯)ä¸­çŒœæµ‹è¾“å‡º(ç›®æ ‡å•è¯)ï¼Œè€Œè¿ç»­è·³æ ¼ä»ç›®æ ‡å•è¯ä¸­çŒœæµ‹ä¸Šä¸‹æ–‡å•è¯ã€‚å®é™…ä¸Šï¼ŒWord2Vec æ˜¯åŸºäº[åˆ†å¸ƒå‡è®¾](https://en.wikipedia.org/wiki/Distributional_semantics#Distributional_hypothesis)çš„ï¼Œå…¶ä¸­æ¯ä¸ªå•è¯çš„ä¸Šä¸‹æ–‡éƒ½åœ¨å®ƒé™„è¿‘çš„å•è¯ä¸­ã€‚å› æ­¤ï¼Œé€šè¿‡æŸ¥çœ‹å®ƒçš„ç›¸é‚»å•è¯ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•é¢„æµ‹ç›®æ ‡å•è¯ã€‚

æ ¹æ® Mikolov çš„è¯´æ³•(åœ¨è¿™ç¯‡æ–‡ç« çš„[ä¸­å¼•ç”¨)ï¼ŒSkip-gram å’Œ CBOW çš„åŒºåˆ«å¦‚ä¸‹:](https://www.quora.com/What-are-the-continuous-bag-of-words-and-skip-gram-architectures)

> ***Skip-gram:*******å¥½ç”¨çš„*** *ç”¨* ***å°‘é‡çš„è®­ç»ƒæ•°æ®*** *ï¼Œç”šè‡³ä»£è¡¨å¥½ç”¨çš„* ***ç”Ÿåƒ»å­—*** *æˆ–è¯ç»„**
> 
> ****CBOW:*** *æ•°å€äº***æ¯”ã€skip-gramã€‘****ç²¾åº¦ç¨å¥½*** ***ä¸º*******é¢‘ç¹*** *å•è¯****

**æ›´è¯¦ç»†åœ°è¯´ï¼Œç”±äº **Skip-gram** å­¦ä¹ ä»ç»™å®šå•è¯é¢„æµ‹ä¸Šä¸‹æ–‡å•è¯ï¼Œåœ¨ä¸¤ä¸ªå•è¯(ä¸€ä¸ªä¸ç»å¸¸å‡ºç°ï¼Œå¦ä¸€ä¸ªæ›´é¢‘ç¹å‡ºç°)å¹¶æ’æ”¾ç½®çš„æƒ…å†µä¸‹ï¼Œå½“æ¶‰åŠåˆ°æœ€å°åŒ–æŸå¤±æ—¶ï¼Œä¸¤è€…å°†å…·æœ‰ç›¸åŒçš„å¤„ç†ï¼Œå› ä¸ºæ¯ä¸ªå•è¯å°†è¢«è§†ä¸ºç›®æ ‡å•è¯å’Œä¸Šä¸‹æ–‡å•è¯ã€‚ä¸ **CBOW** ç›¸æ¯”ï¼Œä¸å¸¸ç”¨çš„å•è¯å°†åªæ˜¯ç”¨äºé¢„æµ‹ç›®æ ‡å•è¯çš„ä¸Šä¸‹æ–‡å•è¯é›†åˆçš„ä¸€éƒ¨åˆ†ã€‚å› æ­¤ï¼Œè¯¥æ¨¡å‹å°†ä¸ºä¸å¸¸ç”¨çš„å•è¯åˆ†é…ä½æ¦‚ç‡ã€‚**

**![](img/ae21c4221a0d5b25792305be78b9363d.png)**

**Fig. 2 â€” Word2Vec â€” CBOW and skip-gram model architectures. Credit: [IDIL](http://idli.group/Natural-Language-Processing-using-Vectoriziation.html)**

# **å®ç°è¿›ç¨‹**

**åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†å®ç° **Skip-gram** æ¶æ„ã€‚ä¸ºäº†ä¾¿äºé˜…è¯»ï¼Œå†…å®¹åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†:**

1.  ****æ•°æ®å‡†å¤‡** â€”å®šä¹‰è¯­æ–™åº“ï¼Œæ¸…ç†ã€è§„èŒƒåŒ–å’Œåˆ†è¯**
2.  ****è¶…å‚æ•°** â€”å­¦ä¹ ç‡ã€æ—¶æœŸã€çª—å£å¤§å°ã€åµŒå…¥å¤§å°**
3.  ****ç”Ÿæˆè®­ç»ƒæ•°æ®** â€”æ„å»ºè¯æ±‡ï¼Œå¯¹å•è¯è¿›è¡Œä¸€æ¬¡æ€§ç¼–ç ï¼Œæ„å»ºå°† id æ˜ å°„åˆ°å•è¯çš„å­—å…¸ï¼Œåä¹‹äº¦ç„¶**
4.  ****æ¨¡å‹è®­ç»ƒ** â€”é€šè¿‡æ­£å‘ä¼ é€’ä¼ é€’ç¼–ç çš„å­—ï¼Œè®¡ç®—é”™è¯¯ç‡ï¼Œä½¿ç”¨åå‘ä¼ æ’­è°ƒæ•´æƒé‡å¹¶è®¡ç®—æŸå¤±**
5.  ****æ¨ç†** â€”è·å–è¯å‘é‡ï¼Œå¯»æ‰¾ç›¸ä¼¼è¯**
6.  ****è¿›ä¸€æ­¥æ”¹è¿›** â€”é€šè¿‡è·³è¿‡ gram è´Ÿé‡‡æ ·(SGNS)å’Œåˆ†å±‚ Softmax åŠ å¿«è®­ç»ƒæ—¶é—´**

# **1.æ•°æ®å‡†å¤‡**

**é¦–å…ˆï¼Œæˆ‘ä»¬ä»ä»¥ä¸‹è¯­æ–™åº“å¼€å§‹:**

> **è‡ªç„¶è¯­è¨€å¤„ç†å’Œæœºå™¨å­¦ä¹ æ—¢æœ‰è¶£åˆä»¤äººå…´å¥‹**

**ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªæ²¡æœ‰æ ‡ç‚¹ç¬¦å·å’Œå¤§å†™å­—æ¯çš„å¥å­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ²¡æœ‰åˆ é™¤åœç”¨è¯â€œå’Œâ€å’Œâ€œæ˜¯â€ã€‚**

**åœ¨ç°å®ä¸­ï¼Œæ–‡æœ¬æ•°æ®æ˜¯éç»“æ„åŒ–çš„ï¼Œå¯èƒ½æ˜¯â€œè„çš„â€ã€‚æ¸…ç†å®ƒä»¬å°†æ¶‰åŠè¯¸å¦‚åˆ é™¤åœç”¨è¯ã€æ ‡ç‚¹ç¬¦å·ã€å°†æ–‡æœ¬è½¬æ¢ä¸ºå°å†™(å®é™…ä¸Šå–å†³äºæ‚¨çš„ä½¿ç”¨æƒ…å†µ)ã€æ›¿æ¢æ•°å­—ç­‰æ­¥éª¤ã€‚KDnuggets æœ‰ä¸€ç¯‡å…³äºè¿™ä¸ªè¿‡ç¨‹çš„ä¼˜ç§€æ–‡ç« ã€‚æˆ–è€…ï¼ŒGensim è¿˜æä¾›äº†ä¸€ä¸ªä½¿ç”¨`[gensim.utils.simple_preprocess](https://radimrehurek.com/gensim/utils.html#gensim.utils.simple_preprocess)`æ‰§è¡Œç®€å•æ–‡æœ¬é¢„å¤„ç†çš„å‡½æ•°ï¼Œå®ƒå°†æ–‡æ¡£è½¬æ¢æˆä¸€ç³»åˆ—å°å†™æ ‡è®°ï¼Œå¿½ç•¥å¤ªçŸ­æˆ–å¤ªé•¿çš„æ ‡è®°ã€‚**

**åœ¨é¢„å¤„ç†ä¹‹åï¼Œæˆ‘ä»¬ç»§ç»­å¯¹è¯­æ–™åº“è¿›è¡Œæ ‡è®°ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬åœ¨ç©ºç™½ä¸Šæ ‡è®°æˆ‘ä»¬çš„è¯­æ–™åº“ï¼Œç»“æœæ˜¯ä¸€ä¸ªå•è¯åˆ—è¡¨:**

> **ã€â€œè‡ªç„¶â€ã€â€œè¯­è¨€â€ã€â€œå¤„ç†â€ã€â€œå’Œâ€ã€â€œæœºå™¨â€ã€â€œå­¦ä¹ â€ã€â€œæ˜¯â€ã€â€œæœ‰è¶£â€ã€â€œå’Œâ€ã€â€œä»¤äººå…´å¥‹â€ã€‘**

# **2.è¶…å‚æ•°**

**åœ¨æˆ‘ä»¬è¿›å…¥å®é™…å®ç°ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€äº›æˆ‘ä»¬ç¨åéœ€è¦çš„è¶…å‚æ•°ã€‚**

**`[window_size]:`å¦‚ä¸Šæ‰€è¿°ï¼Œä¸Šä¸‹æ–‡å•è¯æ˜¯ä¸ç›®æ ‡å•è¯ç›¸é‚»çš„å•è¯ã€‚ä½†æ˜¯è¿™äº›è¯åº”è¯¥æœ‰å¤šè¿œæˆ–å¤šè¿‘æ‰èƒ½è¢«è®¤ä¸ºæ˜¯é‚»å±…å‘¢ï¼Ÿè¿™å°±æ˜¯æˆ‘ä»¬å°†`window_size`å®šä¹‰ä¸º 2 çš„åœ°æ–¹ï¼Œè¿™æ„å‘³ç€åœ¨ç›®æ ‡å•è¯å·¦å³ 2 çš„å•è¯è¢«è®¤ä¸ºæ˜¯ä¸Šä¸‹æ–‡å•è¯ã€‚å‚è€ƒä¸‹é¢çš„å›¾ 3ï¼Œæ³¨æ„ï¼Œå½“çª—å£æ»‘åŠ¨æ—¶ï¼Œè¯­æ–™åº“ä¸­çš„æ¯ä¸ªå•è¯éƒ½å°†æ˜¯ç›®æ ‡å•è¯ã€‚**

**![](img/4acaecbfafd919a5e4a643e34e922afb.png)**

**FIg. 3 â€” With a window_size of 2, the target word is highlighted in orange and context words in green**

**`[n]:`è¿™æ˜¯å•è¯åµŒå…¥çš„ç»´åº¦ï¼Œé€šå¸¸åœ¨ 100 åˆ° 300 ä¹‹é—´ï¼Œå–å†³äºä½ çš„è¯æ±‡é‡ã€‚å°ºå¯¸å¤§å°è¶…è¿‡ 300 å¾€å¾€ä¼šä½¿[æ”¶ç›Šé€’å‡](http://www.aclweb.org/anthology/D14-1162)(å‚è§ç¬¬ 1538 é¡µå›¾ 2 (a))ã€‚è¯·æ³¨æ„ï¼Œå°ºå¯¸ä¹Ÿæ˜¯éšè—å±‚çš„å¤§å°ã€‚**

**`[epochs]:`è¿™æ˜¯è®­ç»ƒçºªå…ƒçš„æ•°ç›®ã€‚åœ¨æ¯ä¸ªæ—¶æœŸï¼Œæˆ‘ä»¬å¾ªç¯æ‰€æœ‰çš„è®­ç»ƒæ ·æœ¬ã€‚**

**`[learning_rate]:`å­¦ä¹ ç‡æ§åˆ¶ç›¸å¯¹äºæŸå¤±æ¢¯åº¦çš„æƒé‡è°ƒæ•´é‡ã€‚**

# **3.ç”ŸæˆåŸ¹è®­æ•°æ®**

**åœ¨è¿™ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬çš„ä¸»è¦ç›®æ ‡æ˜¯å°†æˆ‘ä»¬çš„è¯­æ–™åº“è½¬æ¢æˆç”¨äºè®­ç»ƒ Word2Vec æ¨¡å‹çš„ä¸€æ¬¡æ€§ç¼–ç è¡¨ç¤ºã€‚ä»æˆ‘ä»¬çš„è¯­æ–™åº“ä¸­ï¼Œå›¾ 4 æ”¾å¤§äº† 10 ä¸ªçª—å£(#1 åˆ°#10)ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚æ¯ä¸ªçª—å£ç”±ç›®æ ‡å•è¯åŠå…¶ä¸Šä¸‹æ–‡å•è¯ç»„æˆï¼Œåˆ†åˆ«ä»¥æ©™è‰²å’Œç»¿è‰²çªå‡ºæ˜¾ç¤ºã€‚**

**![](img/089193242c2b56cfa41383f2dea023a4.png)**

**Fig. 4 â€” One-hot encoding for each target word and its context words**

**ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªè®­ç»ƒçª—å£ä¸­çš„ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªå…ƒç´ çš„ç¤ºä¾‹å¦‚ä¸‹æ‰€ç¤º:**

> ***# 1ã€ç›®æ ‡(* ***è‡ªç„¶*** *)ã€‘ã€ã€ä¸Šä¸‹æ–‡(*è¯­è¨€*ã€*å¤„ç†*)ã€‘*
> *ã€åˆ—è¡¨(****)ã€1ï¼Œ0ï¼Œ0ï¼Œ0ï¼Œ0ï¼Œ0ï¼Œ0ï¼Œ0ã€‘***
> åˆ—è¡¨(ã€0ï¼Œ1ï¼Œ0**
> 
> **** * * * * * # 2 è‡³#9 åˆ é™¤*******
> 
> ***#10ã€ç›®æ ‡(* ***ç²¾å½©*** *)ã€‘ã€ã€ä¸Šä¸‹æ–‡(*è¶£å‘³*ã€*ã€*)ã€åˆ—è¡¨(****)ã€0ï¼Œ0ï¼Œ0ï¼Œ0ï¼Œ0ï¼Œ0ï¼Œ1ã€‘****)
> åˆ—è¡¨(***

**ä¸ºäº†ç”Ÿæˆä¸€æ¬¡æ€§è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬é¦–å…ˆåˆå§‹åŒ–`word2vec()`å¯¹è±¡ï¼Œç„¶åé€šè¿‡ä¼ é€’`settings`å’Œ`corpus`ä½œä¸ºå‚æ•°ï¼Œä½¿ç”¨å¯¹è±¡`w2v`è°ƒç”¨å‡½æ•°`generate_training_data`ã€‚**

**åœ¨å‡½æ•°`generate_training_data`ä¸­ï¼Œæˆ‘ä»¬æ‰§è¡Œäº†ä»¥ä¸‹æ“ä½œ:**

1.  **`self.v_count` â€”è¯æ±‡é•¿åº¦(æ³¨æ„ï¼Œè¯æ±‡æ˜¯æŒ‡è¯­æ–™åº“ä¸­å”¯ä¸€è¯çš„æ•°é‡)**
2.  **`self.words_list` â€”è¯æ±‡è¡¨ä¸­çš„å•è¯åˆ—è¡¨**
3.  **`self.word_index` â€”ä»¥è¯æ±‡ä¸­çš„æ¯ä¸ªå…³é”®å­—ä¸ºè¯ï¼Œä»¥å€¼ä¸ºç´¢å¼•çš„å­—å…¸**
4.  **`self.index_word` â€”å­—å…¸ï¼Œæ¯ä¸ªå…³é”®å­—ä½œä¸ºç´¢å¼•ï¼Œå€¼ä½œä¸ºè¯æ±‡ä¸­çš„å•è¯**
5.  **`for`å¾ªç¯ä½¿ç”¨`word2onehot`å‡½æ•°å°†æ¯ä¸ªç›®æ ‡åŠå…¶ä¸Šä¸‹æ–‡å•è¯çš„ä¸€é”®è¡¨ç¤ºè¿½åŠ åˆ°`training_data`ã€‚**

# **4.æ¨¡ç‰¹åŸ¹è®­**

**![](img/735086a81994b3d088ac0da97bfc4c6b.png)**

**Fig. 5 â€” Word2Vec â€” skip-gram network architecture**

**ç”¨æˆ‘ä»¬çš„`training_data`ï¼Œæˆ‘ä»¬ç°åœ¨å‡†å¤‡è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚è®­ç»ƒä»`w2v.train(training_data)`å¼€å§‹ï¼Œæˆ‘ä»¬ä¼ å…¥è®­ç»ƒæ•°æ®å¹¶è°ƒç”¨å‡½æ•°`train`ã€‚**

**Word2Vec æ¨¡å‹ç”±ä¸¤ä¸ªæƒé‡çŸ©é˜µ(`w1`å’Œ`w2`)ç»„æˆï¼Œå‡ºäºæ¼”ç¤ºç›®çš„ï¼Œæˆ‘ä»¬å·²ç»å°†å€¼åˆ†åˆ«åˆå§‹åŒ–ä¸º(9x10)å’Œ(10x9)çš„å½¢çŠ¶ã€‚è¿™æœ‰åŠ©äºè®¡ç®—åå‘ä¼ æ’­è¯¯å·®ï¼Œè¿™å°†åœ¨æœ¬æ–‡åé¢è®¨è®ºã€‚åœ¨å®é™…è®­ç»ƒä¸­ï¼Œæ‚¨åº”è¯¥éšæœºåˆå§‹åŒ–æƒé‡(ä¾‹å¦‚ä½¿ç”¨`np.random.uniform()`)ã€‚ä¸ºæ­¤ï¼Œæ³¨é‡Šç¬¬ 9 è¡Œå’Œç¬¬ 10 è¡Œï¼Œå–æ¶ˆç¬¬ 11 è¡Œå’Œç¬¬ 12 è¡Œçš„æ³¨é‡Šã€‚**

## **è®­ç»ƒâ€”å‘å‰ä¼ çƒ**

**æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¼€å§‹ä½¿ç”¨ç¬¬ä¸€ä¸ªè®­ç»ƒç¤ºä¾‹æ¥è®­ç»ƒæˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªçºªå…ƒï¼Œæ–¹æ³•æ˜¯å°†ä»£è¡¨ç›®æ ‡è¯çš„ä¸€é”®å‘é‡çš„`w_t`ä¼ é€’ç»™`forward_pass`å‡½æ•°ã€‚åœ¨`forward_pass`å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬åœ¨`w1`å’Œ`w_t`ä¹‹é—´æ‰§è¡Œç‚¹ç§¯ä»¥äº§ç”Ÿ`h`(ç¬¬ 24 è¡Œ)ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨`w2`å’Œ`h`æ‰§è¡Œå¦ä¸€ä¸ªç‚¹ç§¯æ¥äº§ç”Ÿè¾“å‡ºå±‚`u`(ç¬¬ 26 è¡Œ)ã€‚æœ€åï¼Œæˆ‘ä»¬è¿è¡Œ`u`åˆ° [softmax](https://en.wikipedia.org/wiki/Softmax_function) æ¥å¼ºåˆ¶æ¯ä¸ªå…ƒç´ åœ¨ 0 å’Œ 1 çš„èŒƒå›´å†…ï¼Œä»è€Œåœ¨è¿”å›é¢„æµ‹çŸ¢é‡`y_pred`ã€éšè—å±‚`h`å’Œè¾“å‡ºå±‚`u`ä¹‹å‰ç»™å‡ºæˆ‘ä»¬é¢„æµ‹çš„æ¦‚ç‡(ç¬¬ 28 è¡Œ)ã€‚**

**æˆ‘é™„ä¸Šäº†ä¸€äº›æˆªå›¾ï¼Œä»¥æ˜¾ç¤ºç¬¬ä¸€ä¸ªçª—å£(#1)ä¸­ç¬¬ä¸€ä¸ªè®­ç»ƒæ ·æœ¬çš„è®¡ç®—ï¼Œå…¶ä¸­ç›®æ ‡è¯æ˜¯â€œè‡ªç„¶â€ï¼Œä¸Šä¸‹æ–‡è¯æ˜¯â€œè¯­è¨€â€å’Œâ€œå¤„ç†â€ã€‚è¯·éšæ„æŸ¥çœ‹è°·æ­Œè¡¨å•[ä¸­çš„å…¬å¼ã€‚](https://docs.google.com/spreadsheets/d/1mgf82Ue7MmQixMm2ZqnT1oWUucj6pEcd2wDs_JgHmco/edit?usp=sharing)**

**![](img/cad175aee60017464f70a1b4828e05ec.png)**

**Fig. 6â€” Calculate hidden layer, output later and softmax**

## **è®­ç»ƒâ€”â€”é”™è¯¯ã€åå‘ä¼ æ’­å’ŒæŸå¤±**

****è¯¯å·®â€”** åˆ©ç”¨`y_pred`ã€`h`å’Œ`u`ï¼Œæˆ‘ä»¬ç»§ç»­è®¡ç®—è¿™ç»„ç‰¹å®šç›®æ ‡å’Œä¸Šä¸‹æ–‡å•è¯çš„è¯¯å·®ã€‚è¿™æ˜¯é€šè¿‡æ€»ç»“`y_pred`å’Œ`w_c`ä¸­æ¯ä¸ªä¸Šä¸‹æ–‡å•è¯ä¹‹é—´çš„å·®å¼‚æ¥å®Œæˆçš„ã€‚**

**![](img/6b9b41fbaaf73ce07dbfd5fdf8df709b.png)**

**Fig. 7 â€” Calculating Error â€” context words are â€˜languageâ€™ and â€˜processingâ€™**

****åå‘ä¼ æ’­** â€”æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨åå‘ä¼ æ’­å‡½æ•°`backprop`ï¼Œé€šè¿‡ä¼ å…¥è¯¯å·®`EI`ã€éšè—å±‚`h`å’Œç›®æ ‡è¯`w_t`çš„å‘é‡ï¼Œè®¡ç®—æˆ‘ä»¬éœ€è¦ä½¿ç”¨å‡½æ•°`backprop`æ”¹å˜æƒé‡çš„è°ƒæ•´é‡ã€‚**

**ä¸ºäº†æ›´æ–°æƒé‡ï¼Œæˆ‘ä»¬å°†å¾…è°ƒæ•´çš„æƒé‡(`dl_dw1`å’Œ`dl_dw2`)ä¹˜ä»¥å­¦ä¹ ç‡ï¼Œç„¶åä»å½“å‰æƒé‡(`w1`å’Œ`w2`)ä¸­å‡å»å®ƒã€‚**

**![](img/f07757b1219ae94c67a1b7a823394ec4.png)**

**Fig. 8 â€” Backpropagation â€” Calculating delta for W1 and W2**

**![](img/b44758d67d661ef6747f95309d4e2344.png)**

**Fig. 9 â€” Backpropagation â€” Adjusting weights to get updated W1 and W2**

****æŸå¤±** â€”æœ€åï¼Œæˆ‘ä»¬æ ¹æ®æŸå¤±å‡½æ•°è®¡ç®—æ¯ä¸ªè®­ç»ƒæ ·æœ¬å®Œæˆåçš„æ€»æŸå¤±ã€‚æ³¨æ„æŸå¤±å‡½æ•°ç”±ä¸¤éƒ¨åˆ†ç»„æˆã€‚ç¬¬ä¸€éƒ¨åˆ†æ˜¯è¾“å‡ºå±‚ä¸­æ‰€æœ‰å…ƒç´ æ€»å’Œçš„è´Ÿå€¼(åœ¨ softmax ä¹‹å‰)ã€‚ç¬¬äºŒéƒ¨åˆ†è·å–ä¸Šä¸‹æ–‡å•è¯çš„æ•°é‡ï¼Œå¹¶ä¹˜ä»¥è¾“å‡ºå±‚ä¸­æ‰€æœ‰å…ƒç´ çš„å’Œçš„å¯¹æ•°(åœ¨æŒ‡æ•°ä¹‹å)ã€‚**

**![](img/7134ef7a5f8a7e8f71cb75a4711052c1.png)**

**Fig. 10 â€” Loss function for Word2Vec skip-gram. Credit: [https://arxiv.org/pdf/1411.2738.pdf](https://arxiv.org/pdf/1411.2738.pdf)**

# **5.æ¨ç†**

**ç°åœ¨æˆ‘ä»¬å·²ç»å®Œæˆäº† 50 ä¸ªçºªå…ƒçš„è®­ç»ƒï¼Œä¸¤ä¸ªæƒé‡(`w1`å’Œ`w2`)ç°åœ¨éƒ½å‡†å¤‡å¥½æ‰§è¡Œæ¨ç†ã€‚**

## **è·å–å•è¯çš„å‘é‡**

**æœ‰äº†ä¸€ç»„è®­ç»ƒå¥½çš„æƒé‡ï¼Œæˆ‘ä»¬å¯ä»¥åšçš„ç¬¬ä¸€ä»¶äº‹å°±æ˜¯æŸ¥çœ‹è¯æ±‡è¡¨ä¸­æŸä¸ªå•è¯çš„å•è¯å‘é‡ã€‚æˆ‘ä»¬å¯ä»¥ç®€å•åœ°é€šè¿‡å¯¹ç…§è®­ç»ƒçš„æƒé‡æ¥æŸ¥æ‰¾å•è¯çš„ç´¢å¼•(`w1`)æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æŸ¥æ‰¾å•è¯â€œmachineâ€çš„å‘é‡ã€‚**

```
**> print(w2v.word_vec("machine"))[ 0.76702922 -0.95673743  0.49207258  0.16240808 -0.4538815  -0.74678226  0.42072706 -0.04147312  0.08947326 -0.24245257]**
```

## **æŸ¥æ‰¾ç›¸ä¼¼çš„å•è¯**

**æˆ‘ä»¬å¯ä»¥åšçš„å¦ä¸€ä»¶äº‹æ˜¯æ‰¾åˆ°ç›¸ä¼¼çš„å•è¯ã€‚å³ä½¿æˆ‘ä»¬çš„è¯æ±‡é‡å¾ˆå°ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥é€šè¿‡è®¡ç®—å•è¯ä¹‹é—´çš„[ä½™å¼¦ç›¸ä¼¼åº¦](https://en.wikipedia.org/wiki/Cosine_similarity)æ¥å®ç°å‡½æ•°`vec_sim`ã€‚**

```
**> w2v.vec_sim("machine", 3)machine 1.0
fun 0.6223490454018772
and 0.5190154215400249**
```

# ****6ã€‚è¿›ä¸€æ­¥æ”¹è¿›****

**å¦‚æœä½ è¿˜åœ¨è¯»è¿™ç¯‡æ–‡ç« ï¼Œå¹²å¾—å¥½ï¼Œè°¢è°¢ä½ ï¼ä½†è¿™å¹¶ä¸æ˜¯ç»“æŸã€‚æ‚¨å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼Œåœ¨ä¸Šé¢çš„åå‘ä¼ æ’­æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬éœ€è¦è°ƒæ•´è®­ç»ƒæ ·æœ¬ä¸­æœªæ¶‰åŠçš„æ‰€æœ‰å…¶ä»–å•è¯çš„æƒé‡ã€‚å¦‚æœä½ çš„è¯æ±‡é‡å¾ˆå¤§(ä¾‹å¦‚å‡ ä¸‡ä¸ª)ï¼Œè¿™ä¸ªè¿‡ç¨‹ä¼šèŠ±è´¹å¾ˆé•¿æ—¶é—´ã€‚**

**ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¸‹é¢æ˜¯ Word2Vec ä¸­çš„ä¸¤ä¸ªç‰¹æ€§ï¼Œæ‚¨å¯ä»¥å®ç°å®ƒä»¬æ¥åŠ å¿«é€Ÿåº¦:**

*   **[Skip-gram Negative Sampling(SGNS)](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/)æœ‰åŠ©äºåŠ å¿«è®­ç»ƒæ—¶é—´ï¼Œæé«˜ç”Ÿæˆçš„å•è¯å‘é‡çš„è´¨é‡ã€‚è¿™æ˜¯é€šè¿‡è®­ç»ƒç½‘ç»œä»…ä¿®æ”¹ä¸€å°éƒ¨åˆ†æƒé‡è€Œä¸æ˜¯æ‰€æœ‰æƒé‡æ¥å®ç°çš„ã€‚å›æƒ³ä¸€ä¸‹ä¸Šé¢çš„ä¾‹å­ï¼Œæˆ‘ä»¬æ¯éš”ä¸€ä¸ªå•è¯æ›´æ–°ä¸€æ¬¡æƒé‡ï¼Œå¦‚æœ vocab çš„å¤§å°å¾ˆå¤§ï¼Œè¿™å°†èŠ±è´¹å¾ˆé•¿çš„*æ—¶é—´ã€‚ä½¿ç”¨ SGNSï¼Œæˆ‘ä»¬åªéœ€è¦æ›´æ–°ç›®æ ‡è¯å’Œå°‘é‡(ä¾‹å¦‚ 5 åˆ° 20 ä¸ª)éšæœºâ€œè´Ÿé¢â€è¯çš„æƒé‡ã€‚***
*   **[åˆ†çº§ Softmax](https://becominghuman.ai/hierarchical-softmax-as-output-activation-function-in-neural-network-1d19089c4f49) ä¹Ÿæ˜¯å¦ä¸€ä¸ªåŠ å¿«è®­ç»ƒæ—¶é—´çš„æŠ€å·§ï¼Œå–ä»£äº†åŸæ¥çš„ Softmaxã€‚ä¸»è¦æ€æƒ³æ˜¯ï¼Œä¸éœ€è¦è¯„ä¼°æ‰€æœ‰çš„è¾“å‡ºèŠ‚ç‚¹æ¥è·å¾—æ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬åªéœ€è¦è¯„ä¼°å®ƒçš„å¤§çº¦ log(ä»¥ 2 ä¸ºåŸºæ•°)ã€‚å®ƒä½¿ç”¨äºŒå‰æ ‘([éœå¤«æ›¼ç¼–ç æ ‘](https://en.wikipedia.org/wiki/Huffman_coding))è¡¨ç¤ºï¼Œå…¶ä¸­è¾“å‡ºå±‚ä¸­çš„èŠ‚ç‚¹è¡¨ç¤ºä¸ºæ ‘å¶ï¼Œå…¶èŠ‚ç‚¹è¡¨ç¤ºä¸ºä¸å…¶å­èŠ‚ç‚¹çš„ç›¸å¯¹æ¦‚ç‡ã€‚**

**![](img/709573703bf9d1a3bf02ca559faeb60b.png)**

**Fig. 11 â€” Hierarchical Binary Tree â€” Path from root to W2 is highlighted**

**é™¤æ­¤ä¹‹å¤–ï¼Œä¸ºä»€ä¹ˆä¸å°è¯•è°ƒæ•´ä»£ç æ¥å®ç°è¿ç»­è¯è¢‹(CBOW)æ¶æ„å‘¢ï¼ŸğŸ˜ƒ**

# **ç»“è®º**

**æœ¬æ–‡æ˜¯å¯¹ Word2Vec å’Œ Word åµŒå…¥ä¸–ç•Œçš„ä»‹ç»ã€‚åŒæ ·å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæœ‰é¢„å…ˆè®­ç»ƒå¥½çš„åµŒå…¥å¯ç”¨ï¼Œå¦‚ [GloVe](https://nlp.stanford.edu/projects/glove/) ã€ [fastText](https://fasttext.cc) å’Œ [ELMo](https://allennlp.org/elmo) å¯ä»¥ç›´æ¥ä¸‹è½½ä½¿ç”¨ã€‚è¿˜æœ‰ Word2Vec çš„æ‰©å±•æ¯”å¦‚ [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html) å’Œæœ€è¿‘çš„ [Code2Vec](https://code2vec.org/) å…¶ä¸­æ–‡æ¡£å’Œä»£ç è¢«è½¬åŒ–ä¸ºå‘é‡ã€‚ğŸ˜‰**

**æœ€åï¼Œæˆ‘è¦æ„Ÿè°¢[ä»»æ°è°­](https://medium.com/u/fdf264797c2a?source=post_page-----13445eebd281--------------------------------)ã€[è±ç±³](https://twitter.com/remykarem)å’Œ[åº¾ä¿¡](http://seowyuxin.com)èŠ±æ—¶é—´è¯„è®ºå’Œé˜…è¯»æœ¬æ–‡çš„è‰ç¨¿ã€‚ğŸ’ª**

***æ³¨:æœ¬æ–‡é¦–å‘äºæˆ‘çš„åšå®¢*[*https://derekchia . com/an-implementation-guide-to-word 2 vec-using-numpy-and-Google-sheets/*](https://derekchia.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets/)**

# **å‚è€ƒ**

**[](https://github.com/nathanrooy/word2vec-from-scratch-with-python/blob/master/word2vec.py) [## nathan rooy/word 2 vec-ç”¨ python ä»å¤´å¼€å§‹

### ç”¨ Python ä»å¤´å¼€å§‹å®ç°äº†ä¸€ä¸ªéå¸¸ç®€å•ã€ç®€å•ã€ä½æ•ˆçš„ skip-gram word2vec

github.com](https://github.com/nathanrooy/word2vec-from-scratch-with-python/blob/master/word2vec.py) [](https://nathanrooy.github.io/posts/2018-03-22/word2vec-from-scratch-with-python-and-numpy/) [## ç”¨ Python å’Œ NumPy ä»å¤´å¼€å§‹ Word2vec

### TLï¼›DR - word2vec å¾ˆç‰›é€¼ï¼Œä¹ŸçœŸçš„å¾ˆç®€å•ã€‚äº†è§£å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œå¹¶å®ç°æ‚¨è‡ªå·±çš„ç‰ˆæœ¬ã€‚è‡ªä»åŠ å…¥â€¦

nathanrooy.github.io](https://nathanrooy.github.io/posts/2018-03-22/word2vec-from-scratch-with-python-and-numpy/) [](https://stats.stackexchange.com/questions/325053/why-word2vec-maximizes-the-cosine-similarity-between-semantically-similar-words) [## word2vec ä¸ºä»€ä¹ˆæœ€å¤§åŒ–è¯­ä¹‰ç›¸ä¼¼è¯ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦

### æ„Ÿè°¢æ‚¨ä¸ºäº¤å‰éªŒè¯æä¾›ç­”æ¡ˆï¼ä½ è¿‡å»çš„ä¸€äº›å›ç­”ä¸å¤ªå—æ¬¢è¿ï¼Œä½ â€¦

stats.stackexchange.com](https://stats.stackexchange.com/questions/325053/why-word2vec-maximizes-the-cosine-similarity-between-semantically-similar-words) [](/hierarchical-softmax-and-negative-sampling-short-notes-worth-telling-2672010dbe08) [## åˆ†å±‚è½¯æœ€å¤§å€¼å’Œè´Ÿé‡‡æ ·:å€¼å¾—è®²è¿°çš„ç®€çŸ­ç¬”è®°

### æ„Ÿè°¢è§‚ä¼—å¯¹æˆ‘ä¸Šä¸€ç¯‡(ä¹Ÿæ˜¯å”¯ä¸€ä¸€ç¯‡)å¸–å­çš„æ„å¤–å’Œæ„‰å¿«çš„å…³æ³¨ï¼Œè¿™ç¯‡å¸–å­æ˜¯çŒ®ç»™â€¦

towardsdatascience.com](/hierarchical-softmax-and-negative-sampling-short-notes-worth-telling-2672010dbe08)**